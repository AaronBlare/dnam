# @package _global_

data_type: eeg
model_sa: xgboost

project_name: ${data_type}_multiclass_trn_val_tst_${model_sa}

is_cv: False
n_splits: 5
is_stratified: True

debug: False
print_config: True
ignore_warnings: True
test_after_training: True

seed: 322
in_dim: 768
out_dim: 3

max_epochs: 500
patience: 10

eeg_data_type: 1st_Day_right_im1_left_im1_background
base_dir: "E:/YandexDisk/EEG/Files/${eeg_data_type}"
work_dir: "${base_dir}/models/${project_name}"
data_dir: "${base_dir}"

is_shap: True
shap_explainer: Tree

# Plot params
num_top_features: 20
num_examples: 3

# specify here default training configuration
defaults:
  - override /trainer: null # choose trainer from 'configs/trainer/'
  - override /model: null
  - override /datamodule: null
  - override /callbacks: none.yaml
  - override /logger: many_loggers.yaml # set logger here or use command line (e.g. `python run.py logger=wandb`)
  - override /hydra/hydra_logging: colorlog
  - override /hydra/job_logging: colorlog

# Separate (train/val separated from test) DataModule
datamodule:
  _target_: src.datamodules.eeg.EEGDataModuleSeparate
  path: ${data_dir}
  features_fn: "${data_dir}/features_df.xlsx"
  classes_fn: "${data_dir}/classes_df.xlsx"
  trn_val_fn: "train_val_df.xlsx"
  tst_fn: "test_df.xlsx"
  outcome: "class"
  batch_size: 64
  trn_val_tst_split: [0.80, 0.20]
  num_workers: 0
  pin_memory: False
  seed: ${seed}
  weighted_sampler: True

# XGBoost model params
xgboost:
  input_dim: ${in_dim}
  output_dim: ${out_dim}
  booster: 'gbtree'
  learning_rate: 0.01
  max_depth: 6
  gamma: 0
  sampling_method: 'uniform'
  subsample: 1
  objective: 'multi:softprob'
  verbosity: 1
  eval_metric: 'mlogloss'
  max_epochs: ${max_epochs}
  patience: ${patience}

# CatBoost model params
catboost:
  input_dim: ${in_dim}
  output_dim: ${out_dim}
  loss_function: 'MultiClass'
  learning_rate: 0.05
  depth: 4
  min_data_in_leaf: 1
  max_leaves: 31
  task_type: 'CPU'
  verbose: 1
  max_epochs: ${max_epochs}
  patience: ${patience}

# LightGBM model params
lightgbm:
  input_dim: ${in_dim}
  output_dim: ${out_dim}
  objective: 'multiclass'
  boosting: 'gbdt'
  learning_rate: 0.01
  num_leaves: 31
  device: 'cpu'
  max_depth: -1
  min_data_in_leaf: 20
  feature_fraction: 0.9
  bagging_fraction: 0.8
  bagging_freq: 5
  verbose: 0
  metric: 'multi_logloss'
  max_epochs: ${max_epochs}
  patience: ${patience}