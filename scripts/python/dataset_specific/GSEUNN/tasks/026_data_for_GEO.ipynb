{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scripts.python.routines.betas import betas_drop_na\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import random\n",
    "import plotly.express as px\n",
    "import copy\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scripts.python.pheno.datasets.filter import filter_pheno\n",
    "from scripts.python.pheno.datasets.features import get_column_name, get_status_dict, get_sex_dict\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "from scipy.stats import mannwhitneyu\n",
    "import plotly.graph_objects as go\n",
    "import pathlib\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from scripts.python.routines.plot.p_value import add_p_value_annotation\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = \"GSEUNN\"\n",
    "path = f\"E:/YandexDisk/Work/pydnameth/datasets\"\n",
    "datasets_info = pd.read_excel(f\"{path}/datasets.xlsx\", index_col='dataset')\n",
    "platform = datasets_info.loc[dataset, 'platform']\n",
    "manifest = get_manifest(platform)\n",
    "\n",
    "path_save = f\"{path}/{platform}/{dataset}/special/026_data_for_GEO\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pheno = pd.read_csv(f\"{path_save}/data/part(v2_ipAGE_159).csv\", index_col='Sample_ID')\n",
    "\n",
    "source_name = 'Whole Blood'\n",
    "organism = 'Homo sapiens'\n",
    "sample_type = 'genomic'\n",
    "\n",
    "pheno.index.name = 'Sample name'\n",
    "pheno['title'] = pheno.index\n",
    "pheno['source name'] = source_name\n",
    "pheno['organism'] = organism\n",
    "pheno['sample type'] = sample_type\n",
    "pheno['idat file Grn'] = pheno['title'] + '_Grn.idat'\n",
    "pheno['idat file Red'] = pheno['title'] + '_Red.idat'\n",
    "pheno['characteristics: Age'] = pheno['Age']\n",
    "pheno['characteristics: Sex'] = pheno['Sex']\n",
    "pheno['characteristics: Group'] = pheno['Group']\n",
    "pheno['characteristics: ipAGE_ID'] = pheno['ipAGE_ID']\n",
    "pheno['molecule'] = 'genomic DNA'\n",
    "pheno['label'] = 'Cy5 and Cy3'\n",
    "pheno['description'] = pheno['source name'] + ' from ' + pheno['Group'] + ' participant ' +  pheno['title']\n",
    "pheno['platform'] = platform\n",
    "\n",
    "pheno.drop(['Sentrix_ID', 'Sentrix_Position', 'Sample_Well', 'Sample_Plate', 'Sample_Group', 'Pool_ID', 'Age', 'Sex', 'Group', 'ipAGE_ID'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_23284/2065872124.py:1: DtypeWarning:\n",
      "\n",
      "Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "betas = pd.read_csv(f\"{path_save}/data/beta_table.txt\", delimiter=\"\\t\", index_col='ID_REF')\n",
    "pvals = pd.read_csv(f\"{path_save}/data/pval_table.txt\", delimiter=\"\\t\", index_col='ID_REF')\n",
    "unmeth = pd.read_csv(f\"{path_save}/data/unmeth_table.txt\", delimiter=\"\\t\", index_col='ID_REF')\n",
    "meth = pd.read_csv(f\"{path_save}/data/meth_table.txt\", delimiter=\"\\t\", index_col='ID_REF')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order is fine\n"
     ]
    }
   ],
   "source": [
    "pheno_ids = pheno.index.tolist()\n",
    "betas_ids = list(betas.columns.values)\n",
    "pvals_ids = list(pvals.columns.values)\n",
    "unmeth_ids = list(unmeth.columns.values)\n",
    "meth_ids = list(meth.columns.values)\n",
    "if  pheno_ids == betas_ids and pheno_ids == pvals_ids and pheno_ids == unmeth_ids and pheno_ids == meth_ids:\n",
    "    print(f\"Order is fine\")\n",
    "else:\n",
    "    raise ValueError(f\"Warning! Order is not the same!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "pvals_ids_new = ['Detection Pval ' + x for x in pvals_ids]\n",
    "pvals_ids_dict = dict(zip(pvals_ids, pvals_ids_new))\n",
    "pvals.rename(columns=pvals_ids_dict, inplace=True)\n",
    "\n",
    "mtx_proc = pd.concat([betas, pvals], axis=1)\n",
    "mtx_proc_ids = []\n",
    "for s_id in range(len(betas_ids)):\n",
    "    mtx_proc_ids.append(betas_ids[s_id])\n",
    "    mtx_proc_ids.append(pvals_ids_new[s_id])\n",
    "mtx_proc = mtx_proc[mtx_proc_ids]\n",
    "\n",
    "pvals_ids_dict_release = {x: 'Detection Pval' for x in pvals_ids_new}\n",
    "mtx_proc.rename(columns=pvals_ids_dict_release, inplace=True)\n",
    "mtx_proc.index.name = 'ID_REF'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "unmeth_ids_new = [x + ' Unmethylated Signal' for x in unmeth_ids]\n",
    "unmeth_ids_dict = dict(zip(unmeth_ids, unmeth_ids_new))\n",
    "unmeth.rename(columns=unmeth_ids_dict, inplace=True)\n",
    "\n",
    "meth_ids_new = [x + ' Methylated Signal' for x in meth_ids]\n",
    "meth_ids_dict = dict(zip(meth_ids, meth_ids_new))\n",
    "meth.rename(columns=meth_ids_dict, inplace=True)\n",
    "\n",
    "mtx_signal = pd.concat([unmeth, meth], axis=1)\n",
    "mtx_signal_ids = []\n",
    "for s_id in range(len(unmeth_ids)):\n",
    "    mtx_signal_ids.append(unmeth_ids_new[s_id])\n",
    "    mtx_signal_ids.append(meth_ids_new[s_id])\n",
    "mtx_signal = mtx_signal[mtx_signal_ids]\n",
    "mtx_signal.index.name = 'ID_REF'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23284/511944576.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mpheno\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_excel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{path_save}/data/samples.xlsx\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmtx_proc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{path_save}/data/mtx_proc.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mmtx_signal\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{path_save}/data/mtx_signal.csv\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36mto_csv\u001B[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[0;32m   3561\u001B[0m         )\n\u001B[0;32m   3562\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3563\u001B[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001B[0m\u001B[0;32m   3564\u001B[0m             \u001B[0mpath_or_buf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3565\u001B[0m             \u001B[0mline_terminator\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mline_terminator\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001B[0m in \u001B[0;36mto_csv\u001B[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[0;32m   1178\u001B[0m             \u001B[0mformatter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfmt\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1179\u001B[0m         )\n\u001B[1;32m-> 1180\u001B[1;33m         \u001B[0mcsv_formatter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1181\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1182\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcreated_buffer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    259\u001B[0m             )\n\u001B[0;32m    260\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 261\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    262\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    263\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001B[0m in \u001B[0;36m_save\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    264\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_need_to_save_header\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    265\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_save_header\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 266\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_save_body\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    267\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    268\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_save_header\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001B[0m in \u001B[0;36m_save_body\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    302\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mstart_i\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mend_i\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    303\u001B[0m                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 304\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_save_chunk\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart_i\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend_i\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    305\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_save_chunk\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart_i\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend_i\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001B[0m in \u001B[0;36m_save_chunk\u001B[1;34m(self, start_i, end_i)\u001B[0m\n\u001B[0;32m    313\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m         \u001B[0mix\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_index\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mslicer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_format_native_types\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_number_format\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 315\u001B[1;33m         libwriters.write_csv_rows(\n\u001B[0m\u001B[0;32m    316\u001B[0m             \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    317\u001B[0m             \u001B[0mix\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\dnam\\lib\\site-packages\\pandas\\_libs\\writers.pyx\u001B[0m in \u001B[0;36mpandas._libs.writers.write_csv_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pheno.to_excel(f\"{path_save}/data/samples.xlsx\", index=True)\n",
    "mtx_proc.to_csv(f\"{path_save}/data/mtx_proc.csv\", index=True)\n",
    "mtx_signal.to_csv(f\"{path_save}/data/mtx_signal.csv\", index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}