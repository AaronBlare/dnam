{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scripts.python.routines.betas import betas_drop_na\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import shutil\n",
    "import random\n",
    "import plotly.express as px\n",
    "import copy\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scripts.python.pheno.datasets.filter import filter_pheno\n",
    "from scripts.python.pheno.datasets.features import get_column_name, get_status_dict, get_sex_dict\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "from scipy.stats import mannwhitneyu\n",
    "import plotly.graph_objects as go\n",
    "import pathlib\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from scripts.python.routines.plot.p_value import add_p_value_annotation\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = \"GSEUNN\"\n",
    "path = f\"E:/YandexDisk/Work/pydnameth/datasets\"\n",
    "datasets_info = pd.read_excel(f\"{path}/datasets.xlsx\", index_col='dataset')\n",
    "platform = datasets_info.loc[dataset, 'platform']\n",
    "manifest = get_manifest(platform)\n",
    "\n",
    "path_save = f\"{path}/{platform}/{dataset}/special/026_data_for_GEO\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pheno = pd.read_csv(f\"{path_save}/data/part(v2_ipAGE_159).csv\", index_col='Sample_ID')\n",
    "\n",
    "source_name = 'Whole Blood'\n",
    "organism = 'Homo sapiens'\n",
    "sample_type = 'genomic'\n",
    "\n",
    "pheno.index.name = 'Sample name'\n",
    "pheno['title'] = pheno.index\n",
    "pheno['source name'] = source_name\n",
    "pheno['organism'] = organism\n",
    "pheno['sample type'] = sample_type\n",
    "pheno['idat file Grn'] = pheno['title'] + '_Grn.idat'\n",
    "pheno['idat file Red'] = pheno['title'] + '_Red.idat'\n",
    "pheno['characteristics: Age'] = pheno['Age']\n",
    "pheno['characteristics: Sex'] = pheno['Sex']\n",
    "pheno['characteristics: Group'] = pheno['Group']\n",
    "pheno['characteristics: ipAGE_ID'] = pheno['ipAGE_ID']\n",
    "pheno['molecule'] = 'genomic DNA'\n",
    "pheno['label'] = 'Cy5 and Cy3'\n",
    "pheno['description'] = pheno['source name'] + ' from ' + pheno['Group'] + ' participant ' +  pheno['title']\n",
    "pheno['platform'] = platform\n",
    "\n",
    "pheno.drop(['Sentrix_ID', 'Sentrix_Position', 'Sample_Well', 'Sample_Plate', 'Sample_Group', 'Pool_ID', 'Age', 'Sex', 'Group', 'ipAGE_ID'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "betas = pd.read_csv(f\"{path_save}/data/beta_table.txt\", delimiter=\"\\t\", index_col='ID_REF')\n",
    "pvals = pd.read_csv(f\"{path_save}/data/pval_table.txt\", delimiter=\"\\t\", index_col='ID_REF')\n",
    "unmeth = pd.read_csv(f\"{path_save}/data/unmeth_table.txt\", delimiter=\"\\t\", index_col='ID_REF')\n",
    "meth = pd.read_csv(f\"{path_save}/data/meth_table.txt\", delimiter=\"\\t\", index_col='ID_REF')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order is fine\n"
     ]
    }
   ],
   "source": [
    "pheno_ids = pheno.index.tolist()\n",
    "betas_ids = list(betas.columns.values)\n",
    "pvals_ids = list(pvals.columns.values)\n",
    "unmeth_ids = list(unmeth.columns.values)\n",
    "meth_ids = list(meth.columns.values)\n",
    "if  pheno_ids == betas_ids and pheno_ids == pvals_ids and pheno_ids == unmeth_ids and pheno_ids == meth_ids:\n",
    "    print(f\"Order is fine\")\n",
    "else:\n",
    "    raise ValueError(f\"Warning! Order is not the same!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pvals_ids_new = ['Detection Pval ' + x for x in pvals_ids]\n",
    "pvals_ids_dict = dict(zip(pvals_ids, pvals_ids_new))\n",
    "pvals.rename(columns=pvals_ids_dict, inplace=True)\n",
    "\n",
    "mtx_proc = pd.concat([betas, pvals], axis=1)\n",
    "mtx_proc_ids = []\n",
    "for s_id in range(len(betas_ids)):\n",
    "    mtx_proc_ids.append(betas_ids[s_id])\n",
    "    mtx_proc_ids.append(pvals_ids_new[s_id])\n",
    "mtx_proc = mtx_proc[mtx_proc_ids]\n",
    "mtx_proc.index.name = 'ID_REF'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "unmeth_ids_new = [x + ' Unmethylated Signal' for x in unmeth_ids]\n",
    "unmeth_ids_dict = dict(zip(unmeth_ids, unmeth_ids_new))\n",
    "unmeth.rename(columns=unmeth_ids_dict, inplace=True)\n",
    "\n",
    "meth_ids_new = [x + ' Methylated Signal' for x in meth_ids]\n",
    "meth_ids_dict = dict(zip(meth_ids, meth_ids_new))\n",
    "meth.rename(columns=meth_ids_dict, inplace=True)\n",
    "\n",
    "mtx_signal = pd.concat([unmeth, meth], axis=1)\n",
    "mtx_signal_ids = []\n",
    "for s_id in range(len(unmeth_ids)):\n",
    "    mtx_signal_ids.append(unmeth_ids_new[s_id])\n",
    "    mtx_signal_ids.append(meth_ids_new[s_id])\n",
    "mtx_signal = mtx_signal[mtx_signal_ids]\n",
    "mtx_signal.index.name = 'ID_REF'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pheno.to_excel(f\"{path_save}/data/samples.xlsx\", index=True)\n",
    "mtx_proc.to_csv(f\"{path_save}/data/mtx_proc.csv\", index=True)\n",
    "mtx_signal.to_csv(f\"{path_save}/data/mtx_signal.csv\", index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "for fn in list(pheno.loc[:, 'idat file Grn'].values) + list(pheno.loc[:, 'idat file Red'].values):\n",
    "    shutil.copy2(f\"{path}/{platform}/{dataset}/raw/idat/{fn}\", f\"{path_save}/idat\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}