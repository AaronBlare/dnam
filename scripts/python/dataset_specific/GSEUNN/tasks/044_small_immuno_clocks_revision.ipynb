{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/044_small_immuno_clocks_revision\"\n",
    "pathlib.Path(f\"{path}\").mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Prepare additional test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/data_origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "indexes_not_origin = df_all.index.difference(df_origin.index)\n",
    "df_all[\"parts_danet\"] = df_all[\"Region\"].str.cat(df_all[[\"Status\"]].astype(str), sep=\"_\")\n",
    "df_all[\"Split\"] = \"tst\"\n",
    "\n",
    "df_new = pd.concat([df_origin, df_all.loc[indexes_not_origin, :]])\n",
    "df_new.to_excel(f\"{path}/all_for_test.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create new dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/origin/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "\n",
    "df_res = pd.read_excel(f\"{path}/origin/models/danet_inference/runs/2023-04-12_12-16-05/df.xlsx\", index_col=0)\n",
    "\n",
    "indexes_test_ctrl_central = df_res.index[(df_res[\"parts_danet\"] == \"Central_Control\")].values\n",
    "print(len(indexes_test_ctrl_central))\n",
    "df_test_ctrl_central = df_all.loc[indexes_test_ctrl_central, :].copy()\n",
    "df_test_ctrl_central[\"parts_danet\"] = 'tst_ctrl_central'\n",
    "df_test_ctrl_central[\"Split\"] = 'tst_ctrl_central'\n",
    "\n",
    "indexes_test_ctrl_yakutia = df_res.index[(df_res[\"parts_danet\"] == \"Yakutia_Control\")].values\n",
    "print(len(indexes_test_ctrl_yakutia))\n",
    "df_test_ctrl_yakutia = df_all.loc[indexes_test_ctrl_yakutia, :].copy()\n",
    "df_test_ctrl_yakutia[\"parts_danet\"] = 'tst_ctrl_yakutia'\n",
    "df_test_ctrl_yakutia[\"Split\"] = 'tst_ctrl_yakutia'\n",
    "\n",
    "df_test_esrd = pd.read_excel(\"D:/YandexDisk/Work/pydnameth/draft/02_geroscience/supplementary/part(v2)/1/SupplementaryTable2.xlsx\", index_col=0)\n",
    "indexes_test_esrd = df_test_esrd.index[df_test_esrd[\"Group\"] == \"Disease\"].values\n",
    "df_test_esrd = df_all.loc[indexes_test_esrd, :]\n",
    "df_test_esrd[\"parts_danet\"] = 'tst_esrd'\n",
    "df_test_esrd[\"Split\"] = 'tst_esrd'\n",
    "\n",
    "df_new = pd.concat([df_origin, df_test_ctrl_central, df_test_ctrl_yakutia, df_test_esrd])\n",
    "df_new.to_excel(f\"{path}/data_wtf.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = 'widedeep_ft_transformer_trn_val_tst'\n",
    "\n",
    "part_check = \"tst_ctrl_all\"\n",
    "part_check_thld_mean = 7.5\n",
    "df = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == \"tst_ctrl_all\"].values\n",
    "\n",
    "path_runs = f\"{path}/models/46_trn_val_tst/{model}/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_val_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "df_samples_test = pd.DataFrame(index=files, columns=samples_test)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    df_pred = pd.read_excel(f\"{head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred = df_pred.loc[df_pred[part_col] == part_check, :]\n",
    "    df_pred.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"AbsError\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[file, samples_test] = 0\n",
    "    df_samples_test.loc[file, samples_passed] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "\n",
    "    df_res.at[file, \"passed_test_samples\"] = n_samples_passed\n",
    "\n",
    "    # Validation\n",
    "    df_val = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_val.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_val.at[metric, \"val\"]\n",
    "\n",
    "    # Train\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', 'trn')\n",
    "    df_trn = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_trn\"] = df_trn.at[metric, \"trn\"]\n",
    "\n",
    "    # Test 1\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', f'tst_ctrl_subset')\n",
    "    df_tst = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_tst_ctrl_subset\"] = df_tst.at[metric, \"tst_ctrl_subset\"]\n",
    "\n",
    "    # Test 2\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', f'tst_ctrl_all')\n",
    "    df_tst = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_tst_ctrl_all\"] = df_tst.at[metric, \"tst_ctrl_all\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = [\n",
    "    'selected',\n",
    "    'passed_test_samples',\n",
    "    'train_more_val',\n",
    "    'mean_absolute_error_trn',\n",
    "    'mean_absolute_error_val',\n",
    "    'pearson_corr_coef_trn',\n",
    "    'pearson_corr_coef_val',\n",
    "    'mean_absolute_error_cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val',\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")\n",
    "df_samples_test.to_excel(f\"{path_runs}/test_samples.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Decider for central"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_all\"\n",
    "part_check_thld_mean = 8.43\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == \"tst_ctrl_all\"].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "    path_head = path_head.replace('/46/', '/46_trn_val_tst/', 1)\n",
    "\n",
    "    file_val = glob(f\"{path_head}/metrics_val_best_*.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "\n",
    "    df_res.at[m, 'val_mae_best'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_mae_mean'] = df_res_val.at['mean_absolute_error_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_mae_std'] = df_res_val.at['mean_absolute_error_cv_std', 'val']\n",
    "    df_res.at[m, 'val_rho_best'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "    df_res.at[m, 'val_rho_mean'] = df_res_val.at['pearson_corr_coef_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_rho_std'] = df_res_val.at['pearson_corr_coef_cv_std', 'val']\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred = df_pred.loc[df_pred[part_col] == part_check, :]\n",
    "    df_pred.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"AbsError\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "    path_head = path_head.replace('/46/', '/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Updating data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/data_full.xlsx\", index_col=0)\n",
    "ids_tst_central_all = df.index[df[\"Split\"] == \"tst_ctrl_central\"].values\n",
    "\n",
    "df_tst_central_include = pd.read_excel(f\"{path}/models/46_trn_val_tst/samples_test_slctd.xlsx\", index_col=0)\n",
    "df_tst_central_include[\"index\"] = df_tst_central_include.index.values\n",
    "df_tst_central_include[\"index\"] = df_tst_central_include[\"index\"].str.rstrip('_copy')\n",
    "ids_tst_central_include = df_tst_central_include[\"index\"].values\n",
    "\n",
    "ids_tst_central_exclude = list(set(ids_tst_central_all) - set(ids_tst_central_include))\n",
    "\n",
    "df.drop(index=ids_tst_central_exclude, inplace=True)\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46\"\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    part_col = df_pred.columns[0]\n",
    "    ids_trn = df_pred.index[df_pred[part_col] == \"trn\"].values\n",
    "    df.loc[ids_trn, f\"best_{m}\"] = \"trn\"\n",
    "    ids_val = df_pred.index[df_pred[part_col] == \"val\"].values\n",
    "    df.loc[ids_val, f\"best_{m}\"] = \"val\"\n",
    "\n",
    "df.to_excel(f\"{path}/data_selected.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Decider for central"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_yakutia\"\n",
    "part_check_thld_mean = 99999\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_selected.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == part_check].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_inference\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    file_val = glob(f\"{path_models}/{m}_inference/runs/*/metrics_val.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "    df_res.at[m, 'val_mae'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_rho'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "\n",
    "    file_tst_central = glob(f\"{path_models}/{m}_inference/runs/*/metrics_tst_ctrl_central.xlsx\")[0]\n",
    "    df_res_tst_central = pd.read_excel(file_tst_central, index_col=0)\n",
    "    df_res.at[m, 'tst_central_mae'] = df_res_tst_central.at['mean_absolute_error', 'tst_ctrl_central']\n",
    "    df_res.at[m, 'tst_central_rho'] = df_res_tst_central.at['pearson_corr_coef', 'tst_ctrl_central']\n",
    "\n",
    "    file_pred = glob(f\"{path_models}/{m}_inference/runs/*/df.xlsx\")[0]\n",
    "    df_pred = pd.read_excel(file_pred, index_col=0)\n",
    "    df_pred = df_pred.loc[df_pred[f\"best_{m}\"] == part_check, :]\n",
    "    df_pred.sort_values([\"Prediction error abs\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"Prediction error abs\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    file_pred = glob(f\"{path_models}/{m}_inference/runs/*/df.xlsx\")[0]\n",
    "    df_pred = pd.read_excel(file_pred, index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_yakutia_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_yakutia_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results_{part_check_thld_mean}.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd_{part_check_thld_mean}.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
