{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/044_small_immuno_clocks_revision\"\n",
    "pathlib.Path(f\"{path}\").mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Prepare additional test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/data_origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "indexes_not_origin = df_all.index.difference(df_origin.index)\n",
    "df_all[\"parts_danet\"] = df_all[\"Region\"].str.cat(df_all[[\"Status\"]].astype(str), sep=\"_\")\n",
    "df_all[\"Split\"] = \"tst\"\n",
    "\n",
    "df_new = pd.concat([df_origin, df_all.loc[indexes_not_origin, :]])\n",
    "df_new.to_excel(f\"{path}/all_for_test.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create new dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/origin/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "\n",
    "df_res = pd.read_excel(f\"{path}/origin/models/danet_inference/runs/2023-04-12_12-16-05/df.xlsx\", index_col=0)\n",
    "indexes_test_ctrl_subset = df_res.index[(df_res[\"parts_danet\"] == \"Central_Control\") & (df_res[\"Prediction error abs\"] < 15)].values\n",
    "print(len(indexes_test_ctrl_subset))\n",
    "df_test_ctrl_subset = df_all.loc[indexes_test_ctrl_subset, :]\n",
    "df_test_ctrl_subset[\"parts_danet\"] = 'tst_ctrl_subset'\n",
    "df_test_ctrl_subset[\"Split\"] = 'tst_ctrl_subset'\n",
    "indexes_test_ctrl_all = df_res.index[(df_res[\"parts_danet\"] == \"Central_Control\")].values\n",
    "print(len(indexes_test_ctrl_all))\n",
    "df_test_ctrl_all = df_all.loc[indexes_test_ctrl_all, :]\n",
    "df_test_ctrl_all[\"index\"] = df_test_ctrl_all.index.values + \"_copy\"\n",
    "df_test_ctrl_all.set_index(\"index\", inplace=True)\n",
    "df_test_ctrl_all[\"parts_danet\"] = 'tst_ctrl_all'\n",
    "df_test_ctrl_all[\"Split\"] = 'tst_ctrl_all'\n",
    "\n",
    "df_test_esrd = pd.read_excel(\"D:/YandexDisk/Work/pydnameth/draft/02_geroscience/supplementary/part(v2)/1/SupplementaryTable2.xlsx\", index_col=0)\n",
    "indexes_test_esrd = df_test_esrd.index[df_test_esrd[\"Group\"] == \"Disease\"].values\n",
    "df_test_esrd = df_all.loc[indexes_test_esrd, :]\n",
    "df_test_esrd[\"parts_danet\"] = 'tst_esrd'\n",
    "df_test_esrd[\"Split\"] = 'tst_esrd'\n",
    "\n",
    "df_new = pd.concat([df_origin, df_test_ctrl_subset, df_test_ctrl_all, df_test_esrd])\n",
    "df_new.to_excel(f\"{path}/data1.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = 'widedeep_ft_transformer_trn_val_tst'\n",
    "\n",
    "part_check = \"tst_ctrl_all\"\n",
    "part_check_thld_mean = 7.5\n",
    "df = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == \"tst_ctrl_all\"].values\n",
    "\n",
    "path_runs = f\"{path}/models/46/{model}/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_val_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "df_samples_test = pd.DataFrame(index=files, columns=samples_test)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    df_pred = pd.read_excel(f\"{head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred = df_pred.loc[df_pred[part_col] == part_check, :]\n",
    "    df_pred.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"AbsError\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[file, samples_test] = 0\n",
    "    df_samples_test.loc[file, samples_passed] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "\n",
    "    df_res.at[file, \"passed_test_samples\"] = n_samples_passed\n",
    "\n",
    "    # Validation\n",
    "    df_val = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_val.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_val.at[metric, \"val\"]\n",
    "\n",
    "    # Train\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', 'trn')\n",
    "    df_trn = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_trn\"] = df_trn.at[metric, \"trn\"]\n",
    "\n",
    "    # Test 1\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', f'tst_ctrl_subset')\n",
    "    df_tst = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_tst_ctrl_subset\"] = df_tst.at[metric, \"tst_ctrl_subset\"]\n",
    "\n",
    "    # Test 2\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', f'tst_ctrl_all')\n",
    "    df_tst = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_tst_ctrl_all\"] = df_tst.at[metric, \"tst_ctrl_all\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = [\n",
    "    'selected',\n",
    "    'passed_test_samples',\n",
    "    'train_more_val',\n",
    "    'mean_absolute_error_trn',\n",
    "    'mean_absolute_error_val',\n",
    "    'pearson_corr_coef_trn',\n",
    "    'pearson_corr_coef_val',\n",
    "    #'mean_absolute_error_tst_ctrl_subset',\n",
    "    #'mean_absolute_error_tst_ctrl_all',\n",
    "    'mean_absolute_error_cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val',\n",
    "    #'mean_absolute_error_cv_mean_tst_ctrl_subset',\n",
    "    #'mean_absolute_error_cv_std_tst_ctrl_subset',\n",
    "    #'mean_absolute_error_cv_mean_tst_ctrl_all',\n",
    "    #'mean_absolute_error_cv_std_tst_ctrl_all',\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")\n",
    "df_samples_test.to_excel(f\"{path_runs}/test_samples.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Decider"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_all\"\n",
    "part_check_thld_mean = 8\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == \"tst_ctrl_all\"].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    file_val = glob(f\"{path_head}/metrics_val_best_*.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "\n",
    "    df_res.at[m, 'val_mae_best'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_mae_mean'] = df_res_val.at['mean_absolute_error_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_mae_std'] = df_res_val.at['mean_absolute_error_cv_std', 'val']\n",
    "    df_res.at[m, 'val_rho_best'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "    df_res.at[m, 'val_rho_mean'] = df_res_val.at['pearson_corr_coef_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_rho_std'] = df_res_val.at['pearson_corr_coef_cv_std', 'val']\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred = df_pred.loc[df_pred[part_col] == part_check, :]\n",
    "    df_pred.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"AbsError\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Test model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_models = f\"{path}/models/46\"\n",
    "\n",
    "model = \"widedeep_tab_net\"\n",
    "\n",
    "tst_ids = pd.read_excel(f\"{path_models}/samples_test_slctd.xlsx\", index_col=0).index.values\n",
    "\n",
    "df_summary = pd.read_excel(f\"{path_models}/{model}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "if len(files_slctd) != 1:\n",
    "    raise ValueError(f\"{model} model selection error\")\n",
    "file_slctd = files_slctd[0]\n",
    "path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "part_col = df_pred.columns[0]\n",
    "trn_val_ids = df_pred.index[df_pred[part_col].isin(['trn', 'val'])].values\n",
    "df_pred = df_pred.loc[list(set(trn_val_ids).union(set(tst_ids))), :]\n",
    "df_pred[\"Part\"] = \"tst\"\n",
    "df_pred.loc[df_pred[part_col] == 'trn', \"Part\"] = \"trn\"\n",
    "df_pred.loc[df_pred[part_col] == 'val', \"Part\"] = \"val\"\n",
    "\n",
    "df_fig = df_pred.loc[:, [\"Age\", 'Prediction', \"Error\", \"Part\"]].copy()\n",
    "plt.figure()\n",
    "sns.set_theme(style='whitegrid')\n",
    "xy_min = df_fig[[\"Age\",'Prediction']].min().min()\n",
    "xy_max = df_fig[[\"Age\",'Prediction']].max().max()\n",
    "xy_ptp = xy_max - xy_min\n",
    "scatter = sns.scatterplot(\n",
    "    data=df_fig,\n",
    "    x=\"Age\",\n",
    "    y=\"Prediction\",\n",
    "    hue=\"Part\",\n",
    "    linewidth=0.3,\n",
    "    alpha=0.75,\n",
    "    edgecolor=\"k\",\n",
    "    s=20,\n",
    "    hue_order=[\"trn\", \"val\", \"tst\"]\n",
    ")\n",
    "scatter.set_xlabel(\"Age\")\n",
    "scatter.set_ylabel(\"Prediction\")\n",
    "scatter.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "scatter.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "plt.gca().plot(\n",
    "    [xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "    [xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"{path_models}/{model}_scatter.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_models}/{model}_scatter.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "sns.set_theme(style='whitegrid')\n",
    "violin = sns.violinplot(\n",
    "    data=df_fig,\n",
    "    x=\"Part\",\n",
    "    y='Error',\n",
    "    scale='width',\n",
    "    saturation=0.75,\n",
    "    order=[\"trn\", \"val\", \"tst\"]\n",
    ")\n",
    "plt.savefig(f\"{path_models}/{model}_violin.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_models}/{model}_violin.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "hist_min = df_fig.loc[:, \"Age\"].min()\n",
    "hist_max = df_fig.loc[:, \"Age\"].max()\n",
    "hist_width = hist_max - hist_min\n",
    "hist_n_bins = 20\n",
    "hist_bin_width = hist_width / hist_n_bins\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.histplot(\n",
    "    data=df_fig,\n",
    "    bins=hist_n_bins,\n",
    "    binrange=(hist_min, hist_max),\n",
    "    binwidth=hist_bin_width,\n",
    "    discrete=False,\n",
    "    multiple='stack',\n",
    "    edgecolor='k',\n",
    "    linewidth=1,\n",
    "    x=\"Age\",\n",
    "    hue=\"Part\",\n",
    "    hue_order=[\"trn\", \"val\", \"tst\"],\n",
    ")\n",
    "plt.savefig(f\"{path_models}/{model}_hist.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_models}/{model}_hist.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
