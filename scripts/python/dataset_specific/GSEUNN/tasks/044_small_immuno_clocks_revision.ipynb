{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/044_small_immuno_clocks_revision\"\n",
    "pathlib.Path(f\"{path}\").mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Prepare additional test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/data_origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "indexes_not_origin = df_all.index.difference(df_origin.index)\n",
    "df_all[\"parts_danet\"] = df_all[\"Region\"].str.cat(df_all[[\"Status\"]].astype(str), sep=\"_\")\n",
    "df_all[\"Split\"] = \"tst\"\n",
    "\n",
    "df_new = pd.concat([df_origin, df_all.loc[indexes_not_origin, :]])\n",
    "df_new.to_excel(f\"{path}/all_for_test.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create new dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/origin/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "\n",
    "df_tst_central_include = pd.read_excel(f\"{path}/origin/samples_test_slctd.xlsx\", index_col=0)\n",
    "df_tst_central_include[\"index\"] = df_tst_central_include.index.values\n",
    "df_tst_central_include[\"index\"] = df_tst_central_include[\"index\"].str.rstrip('_copy')\n",
    "indexes_test_ctrl_central = df_tst_central_include[\"index\"].values\n",
    "print(len(indexes_test_ctrl_central))\n",
    "df_test_ctrl_central = df_all.loc[indexes_test_ctrl_central, :].copy()\n",
    "df_test_ctrl_central[\"parts_danet\"] = 'tst_ctrl_central'\n",
    "df_test_ctrl_central[\"Split\"] = 'tst_ctrl_central'\n",
    "\n",
    "df_res = pd.read_excel(f\"{path}/origin/models/danet_inference/runs/2023-04-12_12-16-05/df.xlsx\", index_col=0)\n",
    "indexes_test_ctrl_yakutia = df_res.index[(df_res[\"parts_danet\"] == \"Yakutia_Control\")].values\n",
    "print(len(indexes_test_ctrl_yakutia))\n",
    "df_test_ctrl_yakutia = df_all.loc[indexes_test_ctrl_yakutia, :].copy()\n",
    "df_test_ctrl_yakutia[\"parts_danet\"] = 'tst_ctrl_yakutia'\n",
    "df_test_ctrl_yakutia[\"Split\"] = 'tst_ctrl_yakutia'\n",
    "\n",
    "indexes_test_esrd = df_all.index[df_all[\"Status\"] == \"ESRD\"].values\n",
    "print(len(indexes_test_esrd))\n",
    "df_test_esrd = df_all.loc[indexes_test_esrd, :]\n",
    "df_test_esrd[\"parts_danet\"] = 'tst_esrd'\n",
    "df_test_esrd[\"Split\"] = 'tst_esrd'\n",
    "\n",
    "df_new = pd.concat([df_origin, df_test_ctrl_central, df_test_ctrl_yakutia, df_test_esrd])\n",
    "\n",
    "df_dead_alive = pd.read_excel(f\"{path}/origin/df_samples_dead_or_alive.xlsx\", index_col=0)\n",
    "inds_dead_alive = df_dead_alive.index[df_dead_alive[\"Dead_Alive\"] == \"Dead\"].values\n",
    "df_new.loc[inds_dead_alive, \"Dead_Alive\"] = \"Dead\"\n",
    "\n",
    "df_new.to_excel(f\"{path}/data_wtf.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = 'danet_trn_val_tst'\n",
    "\n",
    "part_check = \"tst_ctrl_central\"\n",
    "part_check_thld_mean = 7.5\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_tst_ctrl_central = df.index[df[\"Split\"] == \"tst_ctrl_central\"].values\n",
    "\n",
    "path_runs = f\"{path}/models/{model}/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    df_pred = pd.read_excel(f\"{head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred_tst_ctrl_central = df_pred.loc[df_pred[part_col] == part_check, :].copy()\n",
    "    df_pred_tst_ctrl_central.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred_tst_ctrl_central[\"MeanAbsErrorExpanding\"] = df_pred_tst_ctrl_central[\"AbsError\"].expanding().mean()\n",
    "    samples_tst_ctrl_central_passed = df_pred_tst_ctrl_central.index[df_pred_tst_ctrl_central[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    n_samples_passed = len(samples_tst_ctrl_central_passed)\n",
    "\n",
    "    df_res.at[file, \"passed_test_samples\"] = n_samples_passed\n",
    "\n",
    "    # tst_ctrl_central\n",
    "    y_real = df_pred.loc[samples_tst_ctrl_central, \"Age\"]\n",
    "    y_pred = df_pred.loc[samples_tst_ctrl_central, \"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[file, 'mean_absolute_error_tst_ctrl_central'] = mae_tst\n",
    "    df_res.at[file, 'pearson_corr_coef_tst_ctrl_central'] = rho_tst\n",
    "\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_metrics.at[metric, \"val\"]\n",
    "        df_res.at[file, metric + \"_trn\"] = df_metrics.at[metric, \"trn\"]\n",
    "        df_res.at[file, metric + \"_tst_ctrl_central\"] = df_metrics.at[metric, \"tst_ctrl_central\"]\n",
    "        df_res.at[file, metric + \"_trn_val_tst_ctrl_central\"] = df_metrics.at[metric, \"trn_val_tst_ctrl_central\"]\n",
    "        df_res.at[file, metric + \"_val_tst_ctrl_central\"] = df_metrics.at[metric, \"val_tst_ctrl_central\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = [\n",
    "    'selected',\n",
    "    'passed_test_samples',\n",
    "    'train_more_val',\n",
    "    'mean_absolute_error_trn',\n",
    "    'mean_absolute_error_val',\n",
    "    'mean_absolute_error_tst_ctrl_central',\n",
    "    'mean_absolute_error_val_tst_ctrl_central',\n",
    "    'mean_absolute_error_trn_val_tst_ctrl_central',\n",
    "    'pearson_corr_coef_trn',\n",
    "    'pearson_corr_coef_val',\n",
    "    'pearson_corr_coef_tst_ctrl_central',\n",
    "    'pearson_corr_coef_val_tst_ctrl_central',\n",
    "    'pearson_corr_coef_trn_val_tst_ctrl_central',\n",
    "    'mean_absolute_error_cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val',\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Decider for central controls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_all\"\n",
    "part_check_thld_mean = 8.43\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == \"tst_ctrl_all\"].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "    path_head = path_head.replace('/46/', '/46_trn_val_tst/', 1)\n",
    "\n",
    "    file_val = glob(f\"{path_head}/metrics_val_best_*.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "\n",
    "    df_res.at[m, 'val_mae_best'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_mae_mean'] = df_res_val.at['mean_absolute_error_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_mae_std'] = df_res_val.at['mean_absolute_error_cv_std', 'val']\n",
    "    df_res.at[m, 'val_rho_best'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "    df_res.at[m, 'val_rho_mean'] = df_res_val.at['pearson_corr_coef_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_rho_std'] = df_res_val.at['pearson_corr_coef_cv_std', 'val']\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred[part_col].replace({\"tst_ctrl_central\": part_check}, inplace=True)\n",
    "    df_pred = df_pred.loc[df_pred[part_col] == part_check, :]\n",
    "    df_pred.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"AbsError\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Updating data with trn/val splits from best models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    part_col = df_pred.columns[0]\n",
    "    ids_trn = df_pred.index[df_pred[part_col] == \"trn\"].values\n",
    "    df.loc[ids_trn, f\"best_{m}\"] = \"trn\"\n",
    "    ids_val = df_pred.index[df_pred[part_col] == \"val\"].values\n",
    "    df.loc[ids_val, f\"best_{m}\"] = \"val\"\n",
    "\n",
    "df.to_excel(f\"{path}/data_final1.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Inference ckecking and yakutia thresholding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_yakutia\"\n",
    "part_check_thld_mean = 99999\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == part_check].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_inference\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    file_val = glob(f\"{path_models}/{m}_inference/runs/*/metrics_val.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "    df_res.at[m, 'val_mae'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_rho'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "\n",
    "    file_tst_central = glob(f\"{path_models}/{m}_inference/runs/*/metrics_tst_ctrl_central.xlsx\")[0]\n",
    "    df_res_tst_central = pd.read_excel(file_tst_central, index_col=0)\n",
    "    df_res.at[m, 'tst_central_mae'] = df_res_tst_central.at['mean_absolute_error', 'tst_ctrl_central']\n",
    "    df_res.at[m, 'tst_central_rho'] = df_res_tst_central.at['pearson_corr_coef', 'tst_ctrl_central']\n",
    "\n",
    "    file_val = glob(f\"{path_models}/{m}_inference/runs/*/metrics_tst_esrd.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "    df_res.at[m, 'tst_esrd_mae'] = df_res_val.at['mean_absolute_error', 'tst_esrd']\n",
    "    df_res.at[m, 'tst_esrd_rho'] = df_res_val.at['pearson_corr_coef', 'tst_esrd']\n",
    "\n",
    "    file_pred = glob(f\"{path_models}/{m}_inference/runs/*/df.xlsx\")[0]\n",
    "    df_pred = pd.read_excel(file_pred, index_col=0)\n",
    "    df_pred = df_pred.loc[df_pred[f\"best_{m}\"] == part_check, :]\n",
    "    df_pred.sort_values([\"Prediction error abs\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"Prediction error abs\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    file_pred = glob(f\"{path_models}/{m}_inference/runs/*/df.xlsx\")[0]\n",
    "    df_pred = pd.read_excel(file_pred, index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_yakutia_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_yakutia_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results_{part_check_thld_mean}.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd_{part_check_thld_mean}.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Feature selection and dimensionality reduction via SHAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "df_trn_val = df.loc[df[\"Split\"] == \"trn_val\", :]\n",
    "feats = pd.read_excel(f\"{path}/feats_con.xlsx\", index_col=0).index.values\n",
    "path_models = f\"{path}/models/46_shap\"\n",
    "\n",
    "models = {\n",
    "    \"danet\": \"DANet\",\n",
    "    \"widedeep_tab_net\": \"TabNet\",\n",
    "    \"widedeep_saint\": \"SAINT\",\n",
    "    \"widedeep_ft_transformer\": \"FT-Transformer\"\n",
    "}\n",
    "\n",
    "\n",
    "df_fi = pd.DataFrame(index=feats)\n",
    "\n",
    "for m in models:\n",
    "    file_shap = glob(f\"{path_models}/{m}_inference/runs/*/shap/trn_val/shap.xlsx\")[0]\n",
    "    df_shap = pd.read_excel(file_shap, index_col=0)\n",
    "\n",
    "    for f in feats:\n",
    "        df_fi.at[f, models[m]] = df_shap[f].abs().mean()\n",
    "\n",
    "df_fi['Summary'] = df_fi.sum(axis=1)\n",
    "df_fi.sort_values(['Summary'], ascending=[False], inplace=True)\n",
    "df_fi.to_excel(f\"{path_models}/fi.xlsx\", index_label=\"features\")\n",
    "\n",
    "feats_top10 = df_fi.index.values[0:10]\n",
    "df_fig = df_fi.loc[:, list(models.values())]\n",
    "\n",
    "sns.set_theme(style='ticks', font_scale=3)\n",
    "df_fig.plot(kind='bar', stacked=True, color=px.colors.qualitative.D3, figsize=(34, 10), edgecolor='black')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mean(|SHAP values|)')\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path_models}/fi.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_models}/fi.pdf\", bbox_inches='tight')\n",
    "\n",
    "pw.overwrite_axisgrid()\n",
    "sns.set_theme(style='ticks', font_scale=3)\n",
    "ax1 = pw.Brick(figsize=(30, 10))\n",
    "tmp = df_fig.plot(kind='bar', stacked=True, color=px.colors.qualitative.D3, ax=ax1, edgecolor='black')\n",
    "sns.despine(left=False, right=True, bottom=False, top=True, ax=ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('Mean(|SHAP values|)')\n",
    "ax1.text(-4, 45,'A', fontsize=72)\n",
    "ax1.text(-4, -15,'B', fontsize=72)\n",
    "feats_plot = [\"Age\"] + list(feats_top10)\n",
    "sns.set_theme(style=\"ticks\", font_scale=1.5)\n",
    "g1 = sns.PairGrid(df_trn_val, vars=feats_plot)\n",
    "g1.map_diag(plt.hist, bins=15, color='darkred', edgecolor='k')\n",
    "g1.map_upper(sns.scatterplot, color='darkred', s=10, alpha=0.5, edgecolor='k', linewidth=0.2)\n",
    "g1.map_lower(sns.kdeplot, fill=True, cbar=False, cmap='rocket_r', thresh=-0.1)\n",
    "g1.add_legend()\n",
    "for ax in g1.axes.flatten():\n",
    "    ax.get_yaxis().set_label_coords(-0.5, 0.5)\n",
    "ax2 = pw.load_seaborngrid(g1, figsize=(30, 30))\n",
    "(ax1/ax2).savefig(f\"{path_models}/together.pdf\", bbox_inches='tight')\n",
    "(ax1/ax2).savefig(f\"{path_models}/together.png\", bbox_inches='tight', dpi=400)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. trn/val split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.1 Check trn/val identity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_splits\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_trn_val = df.index[df[\"Split\"] == \"trn_val\"].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_folds = {f\"fold_{fold_idx:04d}\": pd.DataFrame(index=samples_trn_val) for fold_idx in range(5)}\n",
    "\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_cv_ids = pd.read_excel(f\"{path_head}/cv_ids.xlsx\", index_col=0)\n",
    "    for fold_idx in range(5):\n",
    "        df_folds[f\"fold_{fold_idx:04d}\"].loc[samples_trn_val, m] = df_cv_ids.loc[samples_trn_val, f\"fold_{fold_idx:04d}\"]\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    df_folds[f\"fold_{fold_idx:04d}\"]['matching'] = df_folds[f\"fold_{fold_idx:04d}\"].eq(df_folds[f\"fold_{fold_idx:04d}\"].iloc[:, 0], axis=0).all(1)\n",
    "    df_folds[f\"fold_{fold_idx:04d}\"].to_excel(f\"{path}/figure_splits/fold_{fold_idx:04d}.xlsx\", index_label=\"index\")\n",
    "    n_matches = df_folds[f\"fold_{fold_idx:04d}\"].index[df_folds[f\"fold_{fold_idx:04d}\"]['matching'] == True].values.shape[0]\n",
    "    print(n_matches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8.2 Plot split histograms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_splits\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_trn_val = df.index[df[\"Split\"] == \"trn_val\"].values\n",
    "df[\"split_id\"] = 0\n",
    "\n",
    "model = \"danet\"\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_folds = {f\"fold_{fold_idx:04d}\": pd.DataFrame(index=samples_trn_val) for fold_idx in range(5)}\n",
    "\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_cv_ids = pd.read_excel(f\"{path_head}/cv_ids.xlsx\", index_col=0)\n",
    "    for fold_idx in range(5):\n",
    "        val_ids = df_cv_ids.index[df_cv_ids[f\"fold_{fold_idx:04d}\"] == \"val\"].values\n",
    "        df.loc[val_ids, \"split_id\"] = fold_idx + 1\n",
    "\n",
    "df_fig = df.loc[samples_trn_val, [\"Age\", \"split_id\"]].copy()\n",
    "df_fig.rename(columns={'split_id': 'Split'}, inplace=True)\n",
    "df_fig.to_excel(f\"{path}/figure_splits/df_fig.xlsx\", index_label=\"index\")\n",
    "\n",
    "hist_bins = np.linspace(0, 110, 12)\n",
    "\n",
    "palette = {x: px.colors.qualitative.Plotly[x+4] for x in range(1, 6)}\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='ticks', font_scale=1.3)\n",
    "hist = sns.histplot(\n",
    "    data=df_fig,\n",
    "    hue_order=list(range(1, 6))[::-1],\n",
    "    bins=hist_bins,\n",
    "    x=\"Age\",\n",
    "    hue=\"Split\",\n",
    "    edgecolor='black',\n",
    "    palette=palette,\n",
    "    multiple=\"stack\",\n",
    ")\n",
    "hist.set(xlim=(0, 110))\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path}/figure_splits/hist.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_splits/hist.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
