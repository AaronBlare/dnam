{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.outliers.iqr import add_iqr_outs_to_df, plot_iqr_outs, plot_iqr_outs_cls\n",
    "from src.utils.outliers.pyod import add_pyod_outs_to_df, plot_pyod_outs, plot_pyod_outs_regression_error\n",
    "from scripts.python.dataset_specific.GSEUNN.tasks.routines_046 import plot_regression_error_distributions, plot_cls_dim_red\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "import importlib\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "from src.utils.verbose import NoStdStreams\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap\n",
    "from openTSNE import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from src.models.tabular.widedeep.tab_net import WDTabNetModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.attacks.evasion import ZooAttack, CarliniL2Method, ElasticNet, NewtonFool\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scripts.python.routines.mvals import expit2\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.kde import KDE\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "\n",
    "from pyod.models.kpca import KPCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.suod import SUOD\n",
    "\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "from torchmetrics import BootStrapper\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Adversarial examples for DNAm data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for ML, convert mvals to betas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam\"\n",
    "\n",
    "df_mvals = pd.read_excel(f\"{path}/mvals.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path}/feats_1000.xlsx\", index_col=0).index.values\n",
    "\n",
    "betas = expit2(df_mvals.loc[:, feats].values)\n",
    "df_betas = df_mvals.copy()\n",
    "df_betas.loc[:, feats] = betas\n",
    "df_betas['Partition'].replace({'Train': 'trn_val', 'Validation': 'tst'}, inplace=True)\n",
    "df_betas.to_excel(f\"{path}/betas.xlsx\", index_label='subject_id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam\"\n",
    "\n",
    "model = 'widedeep_tab_net'\n",
    "\n",
    "path_runs = f\"{path}/models/{model}_trn_val_tst/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "parts = [\n",
    "    'trn',\n",
    "    'val',\n",
    "    'tst',\n",
    "    'val_tst'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    head, tail = os.path.split(file)\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        for part in parts:\n",
    "            df_res.at[file, metric + f\"_{part}\"] = df_metrics.at[metric, part]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res[\"train_worse_val\"] = False\n",
    "df_res.loc[df_res[\"accuracy_weighted_val\"] > df_res[\"accuracy_weighted_trn\"], \"train_worse_val\"] = True\n",
    "\n",
    "df_res[\"File\"] = df_res.index.str.replace(path_runs, '', regex=False)\n",
    "df_res.set_index(\"File\", inplace=True)\n",
    "\n",
    "first_columns = [\n",
    "    'accuracy_weighted_trn',\n",
    "    'accuracy_weighted_val',\n",
    "    'accuracy_weighted_tst',\n",
    "    'accuracy_weighted_val_tst'\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data, models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_type = 'widedeep_tab_net'\n",
    "model_fn = 'best_fold_0000'\n",
    "model_version = 'v2'\n",
    "\n",
    "path = 'D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam'\n",
    "pathlib.Path(f\"{path}/Origin\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/betas.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path}/feats_1000.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "\n",
    "df_pred = pd.read_excel(f\"{path}/models/{model_type}/{model_version}/predictions.xlsx\", index_col=0)\n",
    "df.loc[df.index, ['Real', 'Pred', 'Prob Control', 'Prob Parkinson']] = df_pred.loc[df.index, ['Status', 'pred', 'pred_prob_0', 'pred_prob_1']].values\n",
    "df['Data'] = 'Real'\n",
    "df['Eps'] = 'Origin'\n",
    "\n",
    "col_real = 'Real'\n",
    "col_pred = 'Pred'\n",
    "\n",
    "ids_trn_val = df.index[df['Partition'] == 'trn_val'].values\n",
    "ids_tst = df.index[df['Partition'] == 'tst'].values\n",
    "ids_all = df.index[df['Partition'].isin(['trn_val', 'tst'])].values\n",
    "ids_dict = {\n",
    "    'trn_val': ids_trn_val,\n",
    "    'tst': ids_tst,\n",
    "    'all': ids_all,\n",
    "}\n",
    "\n",
    "model = WDTabNetModel.load_from_checkpoint(checkpoint_path=f\"{path}/models/{model_type}/{model_version}/{model_fn}.ckpt\")\n",
    "model.produce_probabilities = False\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "colors_augs = {\n",
    "    'FAST_ML': px.colors.qualitative.Light24[0],\n",
    "    'GaussianCopula': px.colors.qualitative.Light24[1],\n",
    "    'CTGANSynthesizer': px.colors.qualitative.Light24[2],\n",
    "    'TVAESynthesizer': px.colors.qualitative.Light24[3],\n",
    "    'CopulaGANSynthesizer': px.colors.qualitative.Light24[4],\n",
    "}\n",
    "colors_atks_eps = {\n",
    "    \"MomentumIterative\": px.colors.qualitative.D3[0],\n",
    "    \"BasicIterative\": px.colors.qualitative.D3[1],\n",
    "    \"ProjectedGradientDescent\": px.colors.qualitative.D3[2],\n",
    "    \"FastGradient\": px.colors.qualitative.D3[3],\n",
    "}\n",
    "colors_atks_bss = {\n",
    "    \"ElasticNet\": px.colors.qualitative.G10[7],\n",
    "    \"CarliniL2Method\": px.colors.qualitative.G10[8],\n",
    "    \"ZooAttack\": px.colors.qualitative.G10[9],\n",
    "}\n",
    "colors_atks_eta = {\n",
    "    'NewtonFool': px.colors.qualitative.T10[7],\n",
    "}\n",
    "\n",
    "dim_red_labels = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "    'GRP': ['GRP 1', 'GRP 2'],\n",
    "    'SRP': ['SRP 1', 'SRP 2'],\n",
    "    'IsoMap': ['IsoMap 1', 'IsoMap 2'],\n",
    "    'MBDL': ['MBDL 1', 'MBDL 2'],\n",
    "}\n",
    "\n",
    "pyod_method_names = [\n",
    "    'ECOD',\n",
    "    'LUNAR',\n",
    "    'DeepSVDD',\n",
    "    'VAE',\n",
    "    'LODA',\n",
    "    'INNE',\n",
    "    'IForest',\n",
    "    'SOD',\n",
    "    'KNN',\n",
    "    'CBLOF',\n",
    "    'LOF',\n",
    "    'MCD',\n",
    "    'GMM',\n",
    "    'Sampling',\n",
    "    'SOS',\n",
    "    'COPOD',\n",
    "]\n",
    "\n",
    "thld_iqr_in = 10\n",
    "thld_iqr_out = 100\n",
    "thld_outs_pyod = 1/3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create PyOD models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contamination = 0.1\n",
    "\n",
    "pyod_methods = {\n",
    "    'ECOD': ECOD(contamination=contamination),\n",
    "    'LUNAR': LUNAR(),\n",
    "    'DeepSVDD': DeepSVDD(contamination=contamination, verbose=0),\n",
    "    'VAE': VAE(encoder_neurons=[32, 16, 8], decoder_neurons=[8, 16, 32], contamination=contamination),\n",
    "    'LODA': LODA(contamination=contamination),\n",
    "    'INNE': INNE(contamination=contamination),\n",
    "    'IForest': IForest(contamination=contamination),\n",
    "    'SOD': SOD(contamination=contamination),\n",
    "    'KNN': KNN(contamination=contamination),\n",
    "    'CBLOF': CBLOF(contamination=contamination),\n",
    "    'LOF': LOF(contamination=contamination),\n",
    "    'MCD': MCD(contamination=contamination),\n",
    "    'GMM': GMM(contamination=contamination),\n",
    "    'Sampling': Sampling(contamination=contamination),\n",
    "    'SOS': SOS(contamination=contamination),\n",
    "    'COPOD': COPOD(contamination=contamination),\n",
    "}\n",
    "\n",
    "for method_name, method in (pbar := tqdm(pyod_methods.items())):\n",
    "    pbar.set_description(f\"Processing {method_name}\")\n",
    "    \n",
    "    method.fit(df.loc[ids_trn_val, feats].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dimensionality reduction models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_dim_red = df.loc[ids_trn_val, feats].values\n",
    "random_state = 42\n",
    "dim_red_models = {\n",
    "    'PCA': PCA(n_components=2, whiten=False, random_state=random_state).fit(X_dim_red),\n",
    "    'SVD': TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5, random_state=random_state).fit(X_dim_red),\n",
    "    't-SNE': TSNE(n_components=2, random_state=random_state).fit(X_dim_red),\n",
    "    'GRP': GaussianRandomProjection(n_components=2, eps=0.5, random_state=random_state).fit(X_dim_red),\n",
    "    'SRP': SparseRandomProjection(n_components=2, density='auto', eps=0.5, dense_output=False, random_state=random_state).fit(X_dim_red),\n",
    "    'IsoMap': Isomap(n_components=2, n_neighbors=5).fit(X_dim_red),\n",
    "    'MBDL': MiniBatchDictionaryLearning(n_components=2, batch_size=100, alpha=1, n_iter=25, random_state=random_state).fit(X_dim_red),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Original data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pyod_outs_to_df(df, pyod_methods, feats)\n",
    "add_iqr_outs_to_df(df, df.loc[ids_trn_val, :], feats)\n",
    "for method_name, method in (pbar := tqdm(dim_red_models.items())):\n",
    "    pbar.set_description(f\"Processing {method_name}\")\n",
    "    dim_red_res = method.transform(df.loc[:, feats].values)\n",
    "    df.loc[:, dim_red_labels[method_name][0]] = dim_red_res[:, 0]\n",
    "    df.loc[:, dim_red_labels[method_name][1]] = dim_red_res[:, 1]\n",
    "df.to_excel(f\"{path}/Origin/df.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load original processed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/Origin/df.xlsx\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Original data plots in reduced dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/Origin/dim_red\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_fig = df.loc[:, list(np.concatenate(list(dim_red_labels.values()))) + ['Real', 'Pred', 'Prob Parkinson']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "for method in dim_red_labels:\n",
    "    plot_cls_dim_red(\n",
    "        df=df_fig,\n",
    "        col_class='Status',\n",
    "        cls_names=['Control', 'Parkinson'],\n",
    "        col_prob='Prob Parkinson',\n",
    "        cols_dim_red=dim_red_labels[method],\n",
    "        title='Original',\n",
    "        fn=f\"{path}/Origin/dim_red/{method}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/Origin/feats\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_stat = pd.DataFrame(index=feats, columns=['mw_pval', 'mw_pval_fdr_bh'])\n",
    "for f in feats:\n",
    "    _, df_stat.at[f, 'mw_pval'] = mannwhitneyu(df.loc[df['Real'] == 0, f].values, df.loc[df['Real'] == 1, f].values, alternative='two-sided')\n",
    "_, df_stat.loc[:, 'mw_pval_fdr_bh'], _, _ = multipletests(df_stat.loc[:, \"mw_pval\"], 0.05, method='fdr_bh')\n",
    "df_stat.sort_values(['mw_pval_fdr_bh'], ascending=[True], inplace=True)\n",
    "df_stat[r'$ -\\log_{10}(\\mathrm{p-value})$'] = -np.log10(df_stat['mw_pval_fdr_bh'].astype(float))\n",
    "df_stat.to_excel(f\"{path}/Origin/feats/df_stat.xlsx\", index_label=\"Features\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.set_theme(style='whitegrid')\n",
    "kdeplot = sns.kdeplot(\n",
    "    data=df_stat,\n",
    "    x=r'$ -\\log_{10}(\\mathrm{p-value})$',\n",
    "    color='darkgreen',\n",
    "    linewidth=2,\n",
    "    cut=0,\n",
    "    fill=True,\n",
    "    ax=ax\n",
    ")\n",
    "kdeplot.set_title('Features Distribution Differences')\n",
    "plt.savefig(f\"{path}/Origin/feats/kde_pval.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Origin/feats/kde_pval.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_top_features = 10\n",
    "top_features = list(df_stat.index[0:n_top_features])\n",
    "df_fig = df.loc[:, top_features + ['Real']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_fig = df_fig.melt(id_vars=['Status'], value_vars=list(df_stat.index[0:n_top_features]), var_name='CpG', value_name='Methylation')\n",
    "df_fig['CpG'].replace({x: f\"{x}\\npval: {df_stat.at[x, 'mw_pval_fdr_bh']:0.2e}\" for x in top_features}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 1 * n_top_features))\n",
    "sns.set_theme(style='whitegrid')\n",
    "violin = sns.violinplot(\n",
    "    data=df_fig,\n",
    "    x='Methylation',\n",
    "    y='CpG',\n",
    "    orient='h',\n",
    "    hue='Status',\n",
    "    split=True,\n",
    "    linewidth=1,\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'},\n",
    "    hue_order=['Control', 'Parkinson'],\n",
    "    cut=0,\n",
    "    inner=\"quart\",\n",
    "    ax=ax\n",
    ")\n",
    "plt.savefig(f\"{path}/Origin/feats/violins.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Origin/feats/violins.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_fig = df.loc[:, top_features + ['Prob Parkinson', 'Real']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.set_theme(style='whitegrid')\n",
    "kdeplot = sns.kdeplot(\n",
    "    data=df_fig,\n",
    "    x='Prob Parkinson',\n",
    "    hue='Status',\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'},\n",
    "    hue_order=['Control', 'Parkinson'],\n",
    "    linewidth=2,\n",
    "    cut=0,\n",
    "    fill=True,\n",
    "    ax=ax\n",
    ")\n",
    "plt.savefig(f\"{path}/Origin/feats/kde_proba.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Origin/feats/kde_proba.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# IQR plots\n",
    "pathlib.Path(f\"{path}/Origin/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "plot_iqr_outs(df, feats, 'grey', 'Origin', f\"{path}/Origin/outliers_iqr\", is_msno_plots=False)\n",
    "df_fig = df.loc[:, ['Real', 'Pred', 'n_outs_iqr', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "plot_iqr_outs_cls(\n",
    "    df=df_fig,\n",
    "    path=f\"{path}/Origin/outliers_iqr\",\n",
    "    thld_in=thld_iqr_in,\n",
    "    thld_out=thld_iqr_out,\n",
    "    col_class=\"Status\",\n",
    "    col_pred=\"Pred\",\n",
    "    col_real=\"Real\",\n",
    "    cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    ")\n",
    "\n",
    "# PyOD plots\n",
    "pathlib.Path(f\"{path}/Origin/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "plot_pyod_outs(df, pyod_methods, 'grey', 'Origin', f\"{path}/Origin/outliers_pyod\", n_cols=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Augmented data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_smps = 1000\n",
    "\n",
    "df_aug_sdv_input = df.loc[:, np.concatenate((['Real'], feats))]\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_aug_sdv_input)\n",
    "metadata.update_column('Real', sdtype='categorical')\n",
    "\n",
    "synthesizers = {\n",
    "    'GaussianCopula': GaussianCopulaSynthesizer(metadata),\n",
    "    'CTGANSynthesizer': CTGANSynthesizer(metadata),\n",
    "    'TVAESynthesizer': TVAESynthesizer(metadata),\n",
    "    'CopulaGANSynthesizer': CopulaGANSynthesizer(metadata),\n",
    "    'FAST_ML': SingleTablePreset(metadata, name='FAST_ML'),\n",
    "}\n",
    "\n",
    "for s_name, s in (pbar := tqdm(synthesizers.items())):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    s.fit(\n",
    "        data=df_aug_sdv_input\n",
    "    )\n",
    "    s.save(\n",
    "        filepath=f\"{path_curr}/synthesizer.pkl\"\n",
    "    )\n",
    "    df_aug_sdv = s.sample(\n",
    "        num_rows=n_smps\n",
    "    )\n",
    "    quality_report = evaluate_quality(\n",
    "        df_aug_sdv_input,\n",
    "        df_aug_sdv,\n",
    "        metadata\n",
    "    )\n",
    "    \n",
    "    q_rep_prop = quality_report.get_properties()\n",
    "    q_rep_prop.set_index('Property', inplace=True)\n",
    "    \n",
    "    df_col_shapes = quality_report.get_details(property_name='Column Shapes')\n",
    "    df_col_shapes.sort_values([\"Score\"], ascending=[False], inplace=True)\n",
    "    df_col_shapes.to_excel(f\"{path_curr}/ColumnShapes.xlsx\", index=False)\n",
    "    \n",
    "    df_col_pair_trends = quality_report.get_details(property_name='Column Pair Trends')\n",
    "    df_col_pair_trends.to_excel(f\"{path_curr}/ColumnPairTrends.xlsx\", index=False)\n",
    "    \n",
    "    model.produce_probabilities = True\n",
    "    y_pred_prob = model(torch.from_numpy(np.float32(df_aug_sdv.loc[:, feats].values))).cpu().detach().numpy()\n",
    "    y_pred = np.argmax(y_pred_prob, 1)\n",
    "    df_aug_sdv[\"Pred\"] = y_pred\n",
    "    df_aug_sdv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "    df_aug_sdv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "    \n",
    "    for m, drm in dim_red_models.items():\n",
    "        dim_red_res = drm.transform(df_aug_sdv.loc[:, feats].values)\n",
    "        df_aug_sdv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "        df_aug_sdv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "        \n",
    "    add_iqr_outs_to_df(df_aug_sdv, df.loc[ids_trn_val, :], feats)\n",
    "    add_pyod_outs_to_df(df_aug_sdv, pyod_methods, feats)\n",
    "        \n",
    "    df_aug_sdv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. Attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids_atk = ids_tst\n",
    "\n",
    "art_classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=(len(feats),),\n",
    "    nb_classes=2,\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eps-depended attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[ids_atk, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[ids_atk, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MomentumIterative': MomentumIterativeMethod(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BasicIterative': BasicIterativeMethod(\n",
    "            estimator=art_classifier,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'ProjectedGradientDescent': ProjectedGradientDescentNumpy(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=None,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            random_eps=False,\n",
    "            summary_writer=False,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FastGradient': FastGradientMethod(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path}/Evasion/{attack_name}/eps_{eps_raw:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"Eps\"] = eps_raw\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'MomentumIterative':\n",
    "            df_eps.loc[eps_raw, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_eps.loc[eps_raw, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_eps.to_excel(f\"{path}/Evasion/df_eps.xlsx\", index_label='eps')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_eps = pd.read_excel(f\"{path}/Evasion/df_eps.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['MomentumIterative', 'BasicIterative', 'FastGradient']\n",
    "\n",
    "df_fig = df_eps.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['Eps'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eps',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_eps,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "lines.set_xlabel(r'$\\epsilon$')\n",
    "x_min = 0.0009\n",
    "x_max = 1.05\n",
    "basic = df_eps.at[0.01, f\"Origin_Accuracy\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eps.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eps.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binary Search Steps attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bsss = list(range(1, 11, 1))\n",
    "df_bss = pd.DataFrame(index=bsss)\n",
    "\n",
    "for bss in bsss:\n",
    "\n",
    "    attacks = {\n",
    "        'ElasticNet': ElasticNet(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=1e-3,\n",
    "            binary_search_steps=bss,\n",
    "            max_iter=20,\n",
    "            beta=1e-3,\n",
    "            initial_const=1e-4,\n",
    "            batch_size=1,\n",
    "            decision_rule=\"EN\",\n",
    "            verbose=True,\n",
    "        ),\n",
    "        'CarliniL2Method': CarliniL2Method(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=0.001,\n",
    "            binary_search_steps=bss,\n",
    "            max_iter=20,\n",
    "            initial_const=1e-4,\n",
    "            max_halving=5,\n",
    "            max_doubling=5,\n",
    "            batch_size=1,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'ZooAttack': ZooAttack(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=0.001,\n",
    "            max_iter=20,\n",
    "            binary_search_steps=bss,\n",
    "            initial_const=1e-4,\n",
    "            abort_early=True,\n",
    "            use_resize=False,\n",
    "            use_importance=True,\n",
    "            nb_parallel=16,\n",
    "            batch_size=1,\n",
    "            variable_h=0.001,\n",
    "            verbose=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path}/Evasion/{attack_name}/bss_{bss}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"BSS\"] = bss\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'ElasticNet':\n",
    "            df_bss.loc[bss, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_bss.loc[bss, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_bss.to_excel(f\"{path}/Evasion/df_bss.xlsx\", index_label='eps')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bss = pd.read_excel(f\"{path}/Evasion/df_bss.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['ElasticNet', 'CarliniL2Method', 'ZooAttack']\n",
    "\n",
    "df_fig = df_bss.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['BSS'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"BSS\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='BSS',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_bss,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "lines.set_xlabel('BSS')\n",
    "basic = pd.read_excel(f\"{path}/Evasion/ElasticNet/bss_1/metrics.xlsx\", index_col=0).at['accuracy_weighted', 'Origin']\n",
    "x_min = 0.5\n",
    "x_max = 10.5\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_bss.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_bss.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "etas = np.concatenate([np.geomspace(1e-8, 1e-1, 8), np.geomspace(1e-8, 1e-1, 8) * 5])\n",
    "etas = sorted(etas)\n",
    "\n",
    "df_etas = pd.DataFrame(index=etas)\n",
    "\n",
    "for eta in etas:\n",
    "\n",
    "    attacks = {\n",
    "        'NewtonFool': NewtonFool(\n",
    "            classifier=art_classifier,\n",
    "            max_iter=100,\n",
    "            eta=eta,\n",
    "            batch_size=1,\n",
    "            verbose=True,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path}/Evasion/{attack_name}/eta_{eta:0.2e}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"Eta\"] = f\"{eta:0.2e}\"\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'NewtonFool':\n",
    "            df_etas.loc[eta, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_etas.loc[eta, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_etas.to_excel(f\"{path}/Evasion/df_etas.xlsx\", index_label='eta')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_etas = pd.read_excel(f\"{path}/Evasion/df_etas.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['NewtonFool']\n",
    "\n",
    "df_fig = df_etas.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['Eta'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eta\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eta',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_eta,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "lines.set_xlabel(r'$\\eta$')\n",
    "x_min = 8e-9\n",
    "x_max = 0.6\n",
    "basic = df_etas.at[0.01, f\"Origin_Accuracy\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eta.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eta.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
