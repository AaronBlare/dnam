{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap\n",
    "from openTSNE import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.defences.detector.evasion.binary_input_detector import BinaryInputDetector\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics, get_reg_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Adversarial examples for immunology data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Preparing original data, model and functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_model = f\"{path}/data/immuno/models/SImAge\"\n",
    "path_save = f\"{path}/special/046_adversarial_robustness_toolbox/immunology\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/data/immuno/models/SImAge/data.xlsx\", index_col='sample_id')\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "col_trgt = 'Age'\n",
    "col_pred = 'SImAge'\n",
    "\n",
    "df_preds = pd.read_excel(f\"{path}/data/immuno/models/SImAge/results/predictions.xlsx\", index_col=0)\n",
    "ids_trn = df_preds.index[df_preds['fold_0002'] == 'trn'].values\n",
    "ids_val = df_preds.index[df_preds['fold_0002'] == 'val'].values\n",
    "ids_tst = df_preds.index[df_preds['fold_0002'] == 'tst_ctrl_central'].values\n",
    "ids_all = list(set.union(set(ids_trn), set(ids_val), set(ids_tst)))\n",
    "ids_trn_val = list(set.union(set(ids_trn), set(ids_val)))\n",
    "df = df.loc[ids_all, :]\n",
    "\n",
    "df_X = df.loc[ids_all, feats]\n",
    "\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"{path}/data/immuno/models/SImAge/best_fold_0002.ckpt\")\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "def predict_func_regression(X):\n",
    "    model.produce_probabilities = True\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'continuous': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'categorical': torch.from_numpy(np.int32(X[:, []])),\n",
    "    }\n",
    "    tmp = model(batch)\n",
    "    return tmp.cpu().detach().numpy()\n",
    "\n",
    "art_regressor = PyTorchRegressor(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=[len(feats)],\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=None,\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Dimensionality reduction models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dim_red = df.loc[ids_trn_val, feats].values\n",
    "\n",
    "dim_red_labels = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "    'MDS': ['MDS 1', 'MDS 2'],\n",
    "    'GRP': ['GRP 1', 'GRP 2'],\n",
    "    'SRP': ['SRP 1', 'SRP 2'],\n",
    "    'IsoMap': ['IsoMap 1', 'IsoMap 2'],\n",
    "    'MBDL': ['MBDL 1', 'MBDL 2'],\n",
    "    'ICA': ['ICA 1', 'ICA 2'],\n",
    "}\n",
    "\n",
    "dim_red_models = {\n",
    "    'PCA': PCA(n_components=2, whiten=False).fit(data_dim_red),\n",
    "    'SVD': TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5).fit(data_dim_red),\n",
    "    't-SNE': TSNE(n_components=2).fit(data_dim_red), 'MDS': MDS(n_components=2, metric=True),\n",
    "    'GRP': GaussianRandomProjection(n_components=2, eps=0.5).fit(data_dim_red),\n",
    "    'SRP': SparseRandomProjection(n_components=2, density='auto', eps=0.5, dense_output=False).fit(data_dim_red),\n",
    "    'IsoMap': Isomap(n_components=2, n_neighbors=5).fit(data_dim_red),\n",
    "    'MBDL': MiniBatchDictionaryLearning(n_components=2, batch_size=100, alpha=1, n_iter=25).fit(data_dim_red),\n",
    "    'ICA': FastICA(n_components=2, algorithm='parallel', whiten=True, tol=1e-3, max_iter=1000)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Generate augmented data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "color_augs = {\n",
    "    'FAST_ML': px.colors.qualitative.Light24[0],\n",
    "    'GaussianCopula': px.colors.qualitative.Light24[1],\n",
    "    'CTGANSynthesizer': px.colors.qualitative.Light24[2],\n",
    "    'TVAESynthesizer': px.colors.qualitative.Light24[3],\n",
    "    'CopulaGANSynthesizer': px.colors.qualitative.Light24[4],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Naive augmented data: the same distribution of original feats ===============\n",
    "path_curr = f\"{path_save}/Augmentation/Naive\"\n",
    "pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_bins = 100\n",
    "n_smps = 10000\n",
    "\n",
    "df_aug_naive = pd.DataFrame(columns=np.concatenate((feats, ['Age'])))\n",
    "for f in feats:\n",
    "    f_vals = df.loc[ids_trn_val, f].values\n",
    "    counts, bin_edges = np.histogram(df.loc[ids_trn_val, f].values, bins=n_bins)\n",
    "    df_aug_naive[f] = np.random.choice(bin_edges[:-1], size=n_smps, p=counts/len(f_vals))\n",
    "df_aug_naive[\"SImAge\"] = model(torch.from_numpy(np.float32(df_aug_naive.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "df_aug_naive[\"SImAge Error\"] = df_aug_naive[\"SImAge\"] - df_aug_naive[\"Age\"]\n",
    "df_aug_naive[\"abs(SImAge Error)\"] = df_aug_naive[\"SImAge Error\"].abs()\n",
    "df_aug_naive.to_excel(f\"{path_curr}/df.xlsx\", index_label='index')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Augmented data with Synthetic Data Vault (SDV) ==============================\n",
    "n_smps = 10000\n",
    "\n",
    "df_aug_sdv_input = df.loc[:, np.concatenate((feats, ['Age']))]\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_aug_sdv_input)\n",
    "\n",
    "synthesizers = {\n",
    "    'FAST_ML': SingleTablePreset(metadata, name='FAST_ML'),\n",
    "    'GaussianCopula': GaussianCopulaSynthesizer(metadata),\n",
    "    'CTGANSynthesizer': CTGANSynthesizer(metadata),\n",
    "    'TVAESynthesizer': TVAESynthesizer(metadata),\n",
    "    'CopulaGANSynthesizer': CopulaGANSynthesizer(metadata),\n",
    "}\n",
    "for s_name, s in synthesizers.items():\n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    s.fit(\n",
    "        data=df_aug_sdv_input\n",
    "    )\n",
    "    s.save(\n",
    "        filepath=f\"{path_curr}/synthesizer.pkl\"\n",
    "    )\n",
    "    df_aug_sdv = s.sample(\n",
    "        num_rows=n_smps\n",
    "    )\n",
    "    quality_report = evaluate_quality(\n",
    "        df_aug_sdv_input,\n",
    "        df_aug_sdv,\n",
    "        metadata\n",
    "    )\n",
    "    \n",
    "    q_rep_prop = quality_report.get_properties()\n",
    "    q_rep_prop.set_index('Property', inplace=True)\n",
    "    \n",
    "    df_col_shapes = quality_report.get_details(property_name='Column Shapes')\n",
    "    df_col_shapes.sort_values([\"Score\"], ascending=[False], inplace=True)\n",
    "    df_col_shapes.to_excel(f\"{path_curr}/ColumnShapes.xlsx\", index=False)\n",
    "    fig = plt.figure(figsize=(3, 5))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    barplot = sns.barplot(\n",
    "        data=df_col_shapes,\n",
    "        x=\"Score\",\n",
    "        y=\"Column\",\n",
    "        edgecolor='black',\n",
    "        color=color_augs[s_name],\n",
    "        dodge=False,\n",
    "        orient='h'\n",
    "    )\n",
    "    barplot.set_title(f\"{s_name} Average Score: {q_rep_prop.at['Column Shapes', 'Score']:0.2f}\")\n",
    "    barplot.set_xlabel(f\"KSComplement\")\n",
    "    barplot.set_ylabel(f\"Features\")\n",
    "    plt.savefig(f\"{path_curr}/ColumnShapes.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/ColumnShapes.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_col_pair_trends = quality_report.get_details(property_name='Column Pair Trends')\n",
    "    df_col_pair_trends.to_excel(f\"{path_curr}/ColumnPairTrends.xlsx\", index=False)\n",
    "    feats_plot = np.concatenate((feats, ['Age']))\n",
    "    df_corr_mtx = pd.DataFrame(data=np.zeros(shape=(len(feats_plot), len(feats_plot))), index=feats_plot, columns=feats_plot)\n",
    "    df_pair_mtx = pd.DataFrame(index=feats_plot, columns=feats_plot)\n",
    "    for index, row in df_col_pair_trends.iterrows():\n",
    "        df_corr_mtx.at[row['Column 1'], row['Column 2']] = row['Real Correlation']\n",
    "        df_corr_mtx.at[row['Column 2'], row['Column 1']] = row['Synthetic Correlation']\n",
    "        df_pair_mtx.at[row['Column 1'], row['Column 2']] = row['Score']\n",
    "        df_pair_mtx.at[row['Column 2'], row['Column 1']] = row['Score']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    df_pair_mtx.fillna(value=np.nan, inplace=True)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    heatmap = sns.heatmap(\n",
    "        data=df_pair_mtx,\n",
    "        cmap='plasma',\n",
    "        annot=True,\n",
    "        fmt=\"0.2f\",\n",
    "        cbar_kws={'label': \"Correlation Similarity\"},\n",
    "        mask=df_pair_mtx.isnull()\n",
    "    )\n",
    "    heatmap.set(xlabel=\"\", ylabel=\"\")\n",
    "    heatmap.tick_params(axis='x', rotation=90)\n",
    "    heatmap.set_title(f\"{s_name} Average Score: {q_rep_prop.at['Column Pair Trends', 'Score']:0.2f}\")\n",
    "    plt.savefig(f\"{path_curr}/ColumnPairTrends.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/ColumnPairTrends.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    mtx_to_plot = df_corr_mtx.to_numpy()\n",
    "    mtx_triu = np.triu(mtx_to_plot, +1)\n",
    "    mtx_triu_mask = np.ma.masked_array(mtx_triu, mtx_triu==0)\n",
    "    cmap_triu = plt.get_cmap(\"seismic\").copy()\n",
    "    mtx_tril = np.tril(mtx_to_plot, -1)\n",
    "    mtx_tril_mask = np.ma.masked_array(mtx_tril, mtx_tril==0)\n",
    "    cmap_tril = plt.get_cmap(\"PRGn\").copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    im_triu = ax.imshow(mtx_triu_mask, cmap=cmap_triu, vmin=-1, vmax=1)\n",
    "    cbar_triu = ax.figure.colorbar(im_triu, ax=ax, location='right', shrink=0.7, pad=0.1)\n",
    "    cbar_triu.ax.tick_params(labelsize=10)\n",
    "    cbar_triu.set_label(\"Real Correlation\", horizontalalignment='center', fontsize=12)\n",
    "    im_tril = ax.imshow(mtx_tril_mask, cmap=cmap_tril, vmin=-1, vmax=1)\n",
    "    cbar_tril = ax.figure.colorbar(im_tril, ax=ax, location='right', shrink=0.7, pad=0.1)\n",
    "    cbar_tril.ax.tick_params(labelsize=10)\n",
    "    cbar_tril.set_label(\"Synthetic Correlation\", horizontalalignment='center', fontsize=12)\n",
    "    ax.grid(None)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticks(np.arange(df_corr_mtx.shape[1]))\n",
    "    ax.set_yticks(np.arange(df_corr_mtx.shape[0]))\n",
    "    ax.set_xticklabels(df_corr_mtx.columns.values)\n",
    "    ax.set_yticklabels(df_corr_mtx.index.values)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    for i in range(df_corr_mtx.shape[0]):\n",
    "        for j in range(df_corr_mtx.shape[1]):\n",
    "            color = \"black\"\n",
    "            if i != j:\n",
    "                color = \"black\"\n",
    "                if np.abs(mtx_tril[i, j]) > 0.5:\n",
    "                    color = 'white'\n",
    "                text = ax.text(j, i, f\"{mtx_to_plot[i, j]:0.2f}\", ha=\"center\", va=\"center\", color=color, fontsize=7)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{path_curr}/Correlations.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/Correlations.pdf\", bbox_inches='tight')\n",
    "    plt.clf()  \n",
    "    \n",
    "    df_aug_sdv[\"SImAge\"] = model(torch.from_numpy(np.float32(df_aug_sdv.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "    df_aug_sdv[\"SImAge Error\"] = df_aug_sdv[\"SImAge\"] - df_aug_sdv[\"Age\"]\n",
    "    df_aug_sdv[\"abs(SImAge Error)\"] = df_aug_sdv[\"SImAge Error\"].abs()\n",
    "    df_aug_sdv.to_excel(f\"{path_curr}/df.xlsx\", index_label='index')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Evasion with defences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids_trgt = ids_all\n",
    "\n",
    "epsilons_plot = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "epsilons = sorted(list(set.union(set(epsilons_plot), set(np.linspace(0.1, 1.0, 10)), set(np.linspace(0.01, 0.1, 10)))))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[ids_trn, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[ids_trn, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MI': MomentumIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BI': BasicIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'PGD': ProjectedGradientDescentNumpy(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=None,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            random_eps=False,\n",
    "            summary_writer=False,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FG': FastGradientMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_type, attack in attacks.items():\n",
    "\n",
    "        pathlib.Path(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save adversarial and clean samples for binary input detector\n",
    "        df_adv = pd.DataFrame(data=attack.generate(np.float32(df_X.loc[ids_all, :].values)), columns=feats, index=ids_all)\n",
    "        df_adv.loc[ids_all, 'Dataset'] = df.loc[ids_all, 'Dataset']\n",
    "        df_adv['Index'] = [f\"{sample}_adv\" for sample in ids_all]\n",
    "        df_adv.set_index('Index', inplace=True)\n",
    "        df_adv['DataType'] = 'Adversarial'\n",
    "        df_cln = df.loc[ids_all, list(feats) + ['Dataset']]\n",
    "        df_cln['DataType'] = 'Clean'\n",
    "        df_detector = pd.concat([df_cln, df_adv])\n",
    "        df_detector.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/data_detector.xlsx\", index_label='index')\n",
    "\n",
    "        X = df_X.loc[ids_trgt, :].values\n",
    "        X_adv = attack.generate(np.float32(df_X.loc[ids_trgt, :].values))\n",
    "\n",
    "        y_real = np.float32(df.loc[ids_trgt, target].values)\n",
    "        y_pred = model(torch.from_numpy(X)).cpu().detach().numpy().ravel()\n",
    "        y_pred_adv = model(torch.from_numpy(X_adv)).cpu().detach().numpy().ravel()\n",
    "\n",
    "        metrics = get_reg_metrics()\n",
    "        df_metrics = pd.DataFrame(index=[m for m in metrics])\n",
    "        for m in metrics:\n",
    "            m_val = float(metrics[m][0](torch.from_numpy(y_pred), torch.from_numpy(y_real)).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics[m][0].reset()\n",
    "            m_val = float(metrics[m][0](torch.from_numpy(y_pred_adv), torch.from_numpy(y_real)).numpy())\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            metrics[m][0].reset()\n",
    "        df_metrics.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/metrics.xlsx\")\n",
    "\n",
    "        df_eps.loc[eps_raw, f\"{attack_type}_MAE_Origin\"] = df_metrics.at['mean_absolute_error', 'Origin']\n",
    "        df_eps.loc[eps_raw, f\"{attack_type}_MAE_Attack\"] = df_metrics.at['mean_absolute_error', 'Attack']\n",
    "\n",
    "        df_error = df.loc[ids_trgt, [\"Age\"]].copy()\n",
    "        df_error.loc[ids_trgt, \"Error Origin\"] = y_pred - y_real\n",
    "        df_error.loc[ids_trgt, \"Error Attack\"] = y_pred_adv - y_real\n",
    "        for sample in ids_trgt:\n",
    "            df_eps.loc[eps_raw, f\"{attack_type}_{sample}_ErrorDiff\"] = df_error.loc[sample, \"Error Attack\"] - df_error.loc[sample, \"Error Origin\"]\n",
    "\n",
    "        if eps_raw in epsilons_plot:\n",
    "\n",
    "            n_bins = 100\n",
    "            n_bckgrnd = 100000\n",
    "            df_bckgrnd = pd.DataFrame(columns=feats)\n",
    "            for feat in feats:\n",
    "                f_vals = df.loc[ids_trn_val, feat].values\n",
    "                counts, bin_edges = np.histogram(df.loc[ids_trn_val, feat].values, bins=n_bins)\n",
    "                df_bckgrnd[feat] = np.random.choice(bin_edges[:-1], size=n_bckgrnd, p=counts/len(f_vals))\n",
    "            X_bckgrnd = df_bckgrnd.loc[:, feats].values\n",
    "            df_bckgrnd[\"SImAge\"] = model(torch.from_numpy(np.float32(X_bckgrnd))).cpu().detach().numpy().ravel()\n",
    "\n",
    "            df_dim_red = df.loc[ids_trgt, ['Age']].copy()\n",
    "            df_dim_red.loc[ids_trgt, \"SImAge\"] = y_pred\n",
    "            df_dim_red.loc[ids_trgt, \"Error\"] = df_dim_red.loc[ids_trgt, \"SImAge\"].values - df_dim_red.loc[ids_trgt, \"Age\"].values\n",
    "            df_dim_red_adv = df.loc[ids_trgt, ['Age']].copy()\n",
    "            df_dim_red_adv.loc[ids_trgt, \"SImAge\"] = y_pred_adv\n",
    "            df_dim_red_adv.loc[ids_trgt, \"Error\"] = df_dim_red_adv.loc[ids_trgt, \"SImAge\"].values - df_dim_red_adv.loc[ids_trgt, \"Age\"].values\n",
    "            df_dim_red_adv['index'] = df_dim_red_adv.index.values + '_adv'\n",
    "            df_dim_red_adv.set_index('index', inplace=True)\n",
    "\n",
    "            for m, drm in dim_red_models.items():\n",
    "                dim_red_res = drm.transform(X)\n",
    "                df_dim_red.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "                df_dim_red.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "                dim_red_res_adv = drm.transform(X_adv)\n",
    "                df_dim_red_adv.loc[:, dim_red_labels[m][0]] = dim_red_res_adv[:, 0]\n",
    "                df_dim_red_adv.loc[:, dim_red_labels[m][1]] = dim_red_res_adv[:, 1]\n",
    "                dim_red_res_bckgrnd = drm.transform(X_bckgrnd)\n",
    "                df_bckgrnd.loc[:, dim_red_labels[m][0]] = dim_red_res_bckgrnd[:, 0]\n",
    "                df_bckgrnd.loc[:, dim_red_labels[m][1]] = dim_red_res_bckgrnd[:, 1]\n",
    "            df_dim_red_all = pd.concat([df_dim_red, df_dim_red_adv])\n",
    "            df_dim_red_w_bckgrnd = pd.concat([df_dim_red, df_dim_red_adv, df_bckgrnd])\n",
    "            df_dim_red_all.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/df_dim_red.xlsx\")\n",
    "\n",
    "            for trgt in [\"Age\", \"SImAge\", \"Error\"]:\n",
    "                for m, drm in dim_red_models.items():\n",
    "                    legend_handles = []\n",
    "                    norm = plt.Normalize(df_dim_red_all[trgt].min(), df_dim_red_all[trgt].max())\n",
    "                    sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "                    sm.set_array([])\n",
    "                    fig = plt.figure(figsize=(8, 6))\n",
    "                    sns.set_theme(style='whitegrid')\n",
    "\n",
    "                    scatter = sns.scatterplot(\n",
    "                        data=df_dim_red,\n",
    "                        x=dim_red_labels[m][0],\n",
    "                        y=dim_red_labels[m][1],\n",
    "                        palette='spring',\n",
    "                        hue=trgt,\n",
    "                        linewidth=0.5,\n",
    "                        alpha=0.75,\n",
    "                        edgecolor=\"k\",\n",
    "                        marker='o',\n",
    "                        s=50,\n",
    "                    )\n",
    "                    scatter.get_legend().remove()\n",
    "                    legend_handles.append(mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'))\n",
    "\n",
    "                    scatter = sns.scatterplot(\n",
    "                        data=df_dim_red_adv,\n",
    "                        x=dim_red_labels[m][0],\n",
    "                        y=dim_red_labels[m][1],\n",
    "                        palette='spring',\n",
    "                        hue=trgt,\n",
    "                        linewidth=0.5,\n",
    "                        alpha=0.75,\n",
    "                        edgecolor=\"k\",\n",
    "                        marker='X',\n",
    "                        s=50,\n",
    "                    )\n",
    "                    scatter.get_legend().remove()\n",
    "                    legend_handles.append(mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Attack'))\n",
    "\n",
    "                    plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", mode=\"expand\", borderaxespad=0, ncol=3, frameon=False)\n",
    "                    fig.colorbar(sm, label=trgt)\n",
    "                    plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}.png\", bbox_inches='tight', dpi=400)\n",
    "                    plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}.pdf\", bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "                    if trgt == \"SImAge\":\n",
    "\n",
    "                        n_bins = 100\n",
    "                        x_xtd = (df_dim_red_w_bckgrnd[dim_red_labels[m][0]].max() - df_dim_red_w_bckgrnd[dim_red_labels[m][0]].min()) * 0.075\n",
    "                        x_min = df_dim_red_w_bckgrnd[dim_red_labels[m][0]].min() - x_xtd\n",
    "                        x_max = df_dim_red_w_bckgrnd[dim_red_labels[m][0]].max() + x_xtd\n",
    "                        x_shift = (x_max - x_min) / n_bins\n",
    "                        x_bin_centers = np.linspace(\n",
    "                            start=x_min + 0.5 * x_shift,\n",
    "                            stop=x_max - 0.5 * x_shift,\n",
    "                            num=n_bins\n",
    "                        )\n",
    "                        y_xtd = (df_dim_red_w_bckgrnd[dim_red_labels[m][1]].max() - df_dim_red_w_bckgrnd[dim_red_labels[m][1]].min()) * 0.075\n",
    "                        y_min = df_dim_red_w_bckgrnd[dim_red_labels[m][1]].min() - y_xtd\n",
    "                        y_max = df_dim_red_w_bckgrnd[dim_red_labels[m][1]].max() + y_xtd\n",
    "                        y_shift = (y_max - y_min) / n_bins\n",
    "                        y_bin_centers = np.linspace(\n",
    "                            start=y_min + 0.5 * y_shift,\n",
    "                            stop=y_max - 0.5 * y_shift,\n",
    "                            num=n_bins\n",
    "                        )\n",
    "                        df_heatmap_sum = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "                        df_heatmap_cnt = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "\n",
    "                        xs = df_bckgrnd.loc[:, dim_red_labels[m][0]].values\n",
    "                        xs_ids = np.floor((xs - x_min) / (x_shift + 1e-10)).astype(int)\n",
    "                        ys = df_bckgrnd.loc[:, dim_red_labels[m][1]].values\n",
    "                        ys_ids = np.floor((ys - y_min) / (y_shift + 1e-10)).astype(int)\n",
    "                        zs = df_bckgrnd.loc[:, trgt].values\n",
    "                        for d_id in range(len(xs_ids)):\n",
    "                            df_heatmap_sum.iat[xs_ids[d_id], ys_ids[d_id]] += zs[d_id]\n",
    "                            df_heatmap_cnt.iat[xs_ids[d_id], ys_ids[d_id]] += 1\n",
    "                        df_heatmap = pd.DataFrame(data=df_heatmap_sum.values / df_heatmap_cnt.values, columns=df_heatmap_sum.columns, index=df_heatmap_sum.index)\n",
    "                        df_heatmap.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/heatmap_{trgt}_{m}.xlsx\")\n",
    "\n",
    "                        legend_handles = []\n",
    "                        norm = plt.Normalize(df_dim_red_w_bckgrnd[trgt].min(), df_dim_red_w_bckgrnd[trgt].max())\n",
    "                        sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "                        sm.set_array([])\n",
    "                        fig = plt.figure(figsize=(8, 6))\n",
    "                        sns.set_theme(style='whitegrid')\n",
    "\n",
    "                        plt.gca().imshow(\n",
    "                            X=df_heatmap.transpose().iloc[::-1].values,\n",
    "                            extent=[x_min, x_max, y_min, y_max],\n",
    "                            vmin=df_dim_red_w_bckgrnd[trgt].min(),\n",
    "                            vmax=df_dim_red_w_bckgrnd[trgt].max(),\n",
    "                            aspect=x_shift/y_shift,\n",
    "                            cmap=\"spring\",\n",
    "                            alpha=0.75\n",
    "                        )\n",
    "                        legend_handles.append(mlines.Line2D([], [], marker='s', linestyle='None',markeredgewidth=0, markerfacecolor='lightgrey', markersize=10, label='Background'))\n",
    "\n",
    "                        scatter = sns.scatterplot(\n",
    "                            data=df_dim_red,\n",
    "                            x=dim_red_labels[m][0],\n",
    "                            y=dim_red_labels[m][1],\n",
    "                            palette='spring',\n",
    "                            hue=trgt,\n",
    "                            linewidth=0.5,\n",
    "                            alpha=0.75,\n",
    "                            edgecolor=\"k\",\n",
    "                            marker='o',\n",
    "                            s=50,\n",
    "                        )\n",
    "                        scatter.get_legend().remove()\n",
    "                        legend_handles.append(mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'))\n",
    "\n",
    "                        scatter = sns.scatterplot(\n",
    "                            data=df_dim_red_adv,\n",
    "                            x=dim_red_labels[m][0],\n",
    "                            y=dim_red_labels[m][1],\n",
    "                            palette='spring',\n",
    "                            hue=trgt,\n",
    "                            linewidth=0.5,\n",
    "                            alpha=0.75,\n",
    "                            edgecolor=\"k\",\n",
    "                            marker='X',\n",
    "                            s=50,\n",
    "                        )\n",
    "                        scatter.get_legend().remove()\n",
    "                        legend_handles.append(mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Attack'))\n",
    "\n",
    "                        plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", mode=\"expand\", borderaxespad=0, ncol=3, frameon=False)\n",
    "                        fig.colorbar(sm, label=trgt)\n",
    "                        plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}_w_bckgrnd.png\", bbox_inches='tight', dpi=400)\n",
    "                        plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}_w_bckgrnd.pdf\", bbox_inches='tight')\n",
    "                        plt.close()\n",
    "\n",
    "df_eps.to_excel(f\"{path_save}/df_eps.xlsx\", index_label='eps')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAE from eps plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attacks = {\n",
    "    'MI': \"Momentum Iterative\",\n",
    "    'BI': \"Basic Iterative\",\n",
    "    'PGD': \"Projected Gradient Descent\",\n",
    "    'FG': \"Fast Gradient\"\n",
    "}\n",
    "attacks_palette = {\n",
    "    \"Momentum Iterative\": px.colors.qualitative.D3[0],\n",
    "    \"Basic Iterative\": px.colors.qualitative.D3[1],\n",
    "    \"Projected Gradient Descent\": px.colors.qualitative.D3[2],\n",
    "    \"Fast Gradient\": px.colors.qualitative.D3[3]\n",
    "}\n",
    "df_fig = df_eps.loc[:, [f\"{x}_MAE_Attack\" for x in attacks]].copy()\n",
    "df_fig.rename(columns={f\"{x}_MAE_Attack\": attacks[x] for x in attacks}, inplace=True)\n",
    "df_fig.to_excel(f\"{path_save}/mae_vs_eps.xlsx\", index_label='Eps')\n",
    "df_fig['Eps'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"MAE\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eps',\n",
    "    y=\"MAE\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=attacks_palette,\n",
    "    hue_order=list(attacks_palette.keys()),\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "x_min = 0.009\n",
    "x_max = 1.05\n",
    "mae_basic = df_eps.at[0.01, \"MI_MAE_Origin\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [mae_basic, mae_basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path_save}/mae_vs_eps.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_save}/mae_vs_eps.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attacks = {\n",
    "    'MI': \"Momentum Iterative\",\n",
    "    'BI': \"Basic Iterative\",\n",
    "    'PGD': \"Projected Gradient Descent\",\n",
    "    'FG': \"Fast Gradient\"\n",
    "}\n",
    "for attack in attacks:\n",
    "    df_fig = df_eps.loc[:, [f\"{attack}_{sample}_ErrorDiff\" for sample in ids_trgt]].copy()\n",
    "    for sample in ids_trgt:\n",
    "        func = interp1d(df_fig.index, df_fig[f\"{attack}_{sample}_ErrorDiff\"], kind='cubic')\n",
    "        df_fig[f\"{attack}_{sample}_ErrorDiff\"] = func(df_fig.index)\n",
    "\n",
    "    df_fig['Eps'] = df_fig.index.values\n",
    "    df_fig = df_fig.melt(id_vars=\"Eps\", var_name='ID', value_name=\"Error(Attack) - Error(Origin)\")\n",
    "    fig = plt.figure()\n",
    "    sns.set_theme(style='whitegrid', font_scale=1)\n",
    "    lines = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x='Eps',\n",
    "        y=\"Error(Attack) - Error(Origin)\",\n",
    "        hue=f\"ID\",\n",
    "        markers=False,\n",
    "        dashes=False,\n",
    "        legend=False,\n",
    "        linewidth=0.2,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    plt.savefig(f\"{path_save}/{attack}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path_save}/{attack}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
