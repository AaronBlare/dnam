{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import MDS\n",
    "from openTSNE import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.defences.detector.evasion.binary_input_detector import BinaryInputDetector\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics, get_reg_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Adversarial examples for immunology data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Preparing data, model, functions for black-boxes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special\"\n",
    "path_model = f\"{path}/044_small_immuno_clocks_revision/models/10_trn_val_tst/widedeep_ft_transformer_trn_val_tst/multiruns/2023-05-07_19-40-40_1337/64\"\n",
    "path_save = f\"{path}/046_adversarial_robustness_toolbox/immuno\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/044_small_immuno_clocks_revision/figure_simage/df.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path}/044_small_immuno_clocks_revision/feats_con_top10_new.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "target = 'Age'\n",
    "\n",
    "df_preds = pd.read_excel(f\"{path_model}/predictions.xlsx\", index_col=0)\n",
    "ids_trn = df_preds.index[df_preds['fold_0002'] == 'trn'].values\n",
    "ids_val = df_preds.index[df_preds['fold_0002'] == 'val'].values\n",
    "ids_tst = df_preds.index[df_preds['fold_0002'] == 'tst_ctrl_central'].values\n",
    "ids_all = list(set.union(set(ids_trn), set(ids_val), set(ids_tst)))\n",
    "ids_trn_val = list(set.union(set(ids_trn), set(ids_val)))\n",
    "df = df.loc[ids_all, :]\n",
    "\n",
    "df_X = df.loc[ids_all, feats]\n",
    "\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"{path_model}/best_fold_0002.ckpt\")\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "def predict_func_regression(X):\n",
    "    model.produce_probabilities = True\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'continuous': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'categorical': torch.from_numpy(np.int32(X[:, []])),\n",
    "    }\n",
    "    tmp = model(batch)\n",
    "    return tmp.cpu().detach().numpy()\n",
    "\n",
    "# We don't need optimizer, because model already trained\n",
    "art_regressor = PyTorchRegressor(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=[len(feats)],\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=None,\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Dimensionality reduction models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dim_red_labels = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "}\n",
    "dim_red_models = {}\n",
    "data_dim_red = df.loc[ids_trn_val, feats].values\n",
    "\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "pca.fit(data_dim_red)\n",
    "dim_red_models['PCA'] = pca\n",
    "svd = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5)\n",
    "svd.fit(data_dim_red)\n",
    "dim_red_models['SVD'] = svd\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_emb = tsne.fit(data_dim_red)\n",
    "dim_red_models['t-SNE'] = tsne_emb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Evasion with defences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids_trgt = ids_all\n",
    "\n",
    "epsilons_plot = [0.01] + list(np.linspace(0.1, 1.0, 10))\n",
    "epsilons = sorted(list(set.union(set(epsilons_plot), set(np.linspace(0.1, 1.0, 20)), set(np.linspace(0.01, 0.1, 20)))))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[ids_trn, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[ids_trn, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MI': MomentumIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BI': BasicIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'PGD': ProjectedGradientDescentNumpy(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=None,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            random_eps=False,\n",
    "            summary_writer=False,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FG': FastGradientMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_type, attack in attacks.items():\n",
    "\n",
    "        pathlib.Path(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save adversarial and clean samples for binary input detector\n",
    "        df_adv = pd.DataFrame(data=attack.generate(np.float32(df_X.loc[ids_all, :].values)), columns=feats, index=ids_all)\n",
    "        df_adv.loc[ids_all, 'Dataset'] = df.loc[ids_all, 'Dataset']\n",
    "        df_adv['Index'] = [f\"{sample}_adv\" for sample in ids_all]\n",
    "        df_adv.set_index('Index', inplace=True)\n",
    "        df_adv['DataType'] = 'Adversarial'\n",
    "        df_cln = df.loc[ids_all, list(feats) + ['Dataset']]\n",
    "        df_cln['DataType'] = 'Clean'\n",
    "        df_detector = pd.concat([df_cln, df_adv])\n",
    "        df_detector.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/data_detector.xlsx\", index_label='index')\n",
    "\n",
    "        X = df_X.loc[ids_trgt, :].values\n",
    "        X_adv = attack.generate(np.float32(df_X.loc[ids_trgt, :].values))\n",
    "\n",
    "        y_real = np.float32(df.loc[ids_trgt, target].values)\n",
    "        y_pred = model(torch.from_numpy(X)).cpu().detach().numpy().ravel()\n",
    "        y_pred_adv = model(torch.from_numpy(X_adv)).cpu().detach().numpy().ravel()\n",
    "\n",
    "        metrics = get_reg_metrics()\n",
    "        df_metrics = pd.DataFrame(index=[m for m in metrics])\n",
    "        for m in metrics:\n",
    "            m_val = float(metrics[m][0](torch.from_numpy(y_pred), torch.from_numpy(y_real)).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics[m][0].reset()\n",
    "            m_val = float(metrics[m][0](torch.from_numpy(y_pred_adv), torch.from_numpy(y_real)).numpy())\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            metrics[m][0].reset()\n",
    "        df_metrics.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/metrics.xlsx\")\n",
    "\n",
    "        df_eps.loc[eps_raw, f\"{attack_type}_MAE_Origin\"] = df_metrics.at['mean_absolute_error', 'Origin']\n",
    "        df_eps.loc[eps_raw, f\"{attack_type}_MAE_Attack\"] = df_metrics.at['mean_absolute_error', 'Attack']\n",
    "\n",
    "        df_error = df.loc[ids_trgt, [\"Age\"]].copy()\n",
    "        df_error.loc[ids_trgt, \"Error Origin\"] = y_pred - y_real\n",
    "        df_error.loc[ids_trgt, \"Error Attack\"] = y_pred_adv - y_real\n",
    "        for sample in ids_trgt:\n",
    "            df_eps.loc[eps_raw, f\"{attack_type}_{sample}_ErrorDiff\"] = df_error.loc[sample, \"Error Attack\"] - df_error.loc[sample, \"Error Origin\"]\n",
    "\n",
    "        if eps_raw in epsilons_plot:\n",
    "\n",
    "            n_bins = 100\n",
    "            n_bckgrnd = 100000\n",
    "            df_bckgrnd = pd.DataFrame(columns=feats)\n",
    "            for feat in feats:\n",
    "                f_vals = df.loc[ids_trn_val, feat].values\n",
    "                counts, bin_edges = np.histogram(df.loc[ids_trn_val, feat].values, bins=n_bins)\n",
    "                df_bckgrnd[feat] = np.random.choice(bin_edges[:-1], size=n_bckgrnd, p=counts/len(f_vals))\n",
    "            X_bckgrnd = df_bckgrnd.loc[:, feats].values\n",
    "            df_bckgrnd[\"SImAge\"] = model(torch.from_numpy(np.float32(X_bckgrnd))).cpu().detach().numpy().ravel()\n",
    "\n",
    "            df_dim_red = df.loc[ids_trgt, ['Age']].copy()\n",
    "            df_dim_red.loc[ids_trgt, \"SImAge\"] = y_pred\n",
    "            df_dim_red.loc[ids_trgt, \"Error\"] = df_dim_red.loc[ids_trgt, \"SImAge\"].values - df_dim_red.loc[ids_trgt, \"Age\"].values\n",
    "            df_dim_red_adv = df.loc[ids_trgt, ['Age']].copy()\n",
    "            df_dim_red_adv.loc[ids_trgt, \"SImAge\"] = y_pred_adv\n",
    "            df_dim_red_adv.loc[ids_trgt, \"Error\"] = df_dim_red_adv.loc[ids_trgt, \"SImAge\"].values - df_dim_red_adv.loc[ids_trgt, \"Age\"].values\n",
    "            df_dim_red_adv['index'] = df_dim_red_adv.index.values + '_adv'\n",
    "            df_dim_red_adv.set_index('index', inplace=True)\n",
    "\n",
    "            for m, drm in dim_red_models.items():\n",
    "                dim_red_res = drm.transform(X)\n",
    "                df_dim_red.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "                df_dim_red.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "                dim_red_res_adv = drm.transform(X_adv)\n",
    "                df_dim_red_adv.loc[:, dim_red_labels[m][0]] = dim_red_res_adv[:, 0]\n",
    "                df_dim_red_adv.loc[:, dim_red_labels[m][1]] = dim_red_res_adv[:, 1]\n",
    "                dim_red_res_bckgrnd = drm.transform(X_bckgrnd)\n",
    "                df_bckgrnd.loc[:, dim_red_labels[m][0]] = dim_red_res_bckgrnd[:, 0]\n",
    "                df_bckgrnd.loc[:, dim_red_labels[m][1]] = dim_red_res_bckgrnd[:, 1]\n",
    "            df_dim_red_all = pd.concat([df_dim_red, df_dim_red_adv])\n",
    "            df_dim_red_w_bckgrnd = pd.concat([df_dim_red, df_dim_red_adv, df_bckgrnd])\n",
    "            df_dim_red_all.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/df_dim_red.xlsx\")\n",
    "\n",
    "            for trgt in [\"Age\", \"SImAge\", \"Error\"]:\n",
    "                for m, drm in dim_red_models.items():\n",
    "                    legend_handles = []\n",
    "                    norm = plt.Normalize(df_dim_red_all[trgt].min(), df_dim_red_all[trgt].max())\n",
    "                    sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "                    sm.set_array([])\n",
    "                    fig = plt.figure(figsize=(8, 6))\n",
    "                    sns.set_theme(style='whitegrid')\n",
    "\n",
    "                    scatter = sns.scatterplot(\n",
    "                        data=df_dim_red,\n",
    "                        x=dim_red_labels[m][0],\n",
    "                        y=dim_red_labels[m][1],\n",
    "                        palette='spring',\n",
    "                        hue=trgt,\n",
    "                        linewidth=0.5,\n",
    "                        alpha=0.75,\n",
    "                        edgecolor=\"k\",\n",
    "                        marker='o',\n",
    "                        s=50,\n",
    "                    )\n",
    "                    scatter.get_legend().remove()\n",
    "                    legend_handles.append(mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'))\n",
    "\n",
    "                    scatter = sns.scatterplot(\n",
    "                        data=df_dim_red_adv,\n",
    "                        x=dim_red_labels[m][0],\n",
    "                        y=dim_red_labels[m][1],\n",
    "                        palette='spring',\n",
    "                        hue=trgt,\n",
    "                        linewidth=0.5,\n",
    "                        alpha=0.75,\n",
    "                        edgecolor=\"k\",\n",
    "                        marker='X',\n",
    "                        s=50,\n",
    "                    )\n",
    "                    scatter.get_legend().remove()\n",
    "                    legend_handles.append(mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Attack'))\n",
    "\n",
    "                    plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", mode=\"expand\", borderaxespad=0, ncol=3, frameon=False)\n",
    "                    fig.colorbar(sm, label=trgt)\n",
    "                    plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}.png\", bbox_inches='tight', dpi=400)\n",
    "                    plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}.pdf\", bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "                    if trgt == \"SImAge\":\n",
    "\n",
    "                        n_bins = 100\n",
    "                        x_xtd = (df_dim_red_w_bckgrnd[dim_red_labels[m][0]].max() - df_dim_red_w_bckgrnd[dim_red_labels[m][0]].min()) * 0.075\n",
    "                        x_min = df_dim_red_w_bckgrnd[dim_red_labels[m][0]].min() - x_xtd\n",
    "                        x_max = df_dim_red_w_bckgrnd[dim_red_labels[m][0]].max() + x_xtd\n",
    "                        x_shift = (x_max - x_min) / n_bins\n",
    "                        x_bin_centers = np.linspace(\n",
    "                            start=x_min + 0.5 * x_shift,\n",
    "                            stop=x_max - 0.5 * x_shift,\n",
    "                            num=n_bins\n",
    "                        )\n",
    "                        y_xtd = (df_dim_red_w_bckgrnd[dim_red_labels[m][1]].max() - df_dim_red_w_bckgrnd[dim_red_labels[m][1]].min()) * 0.075\n",
    "                        y_min = df_dim_red_w_bckgrnd[dim_red_labels[m][1]].min() - y_xtd\n",
    "                        y_max = df_dim_red_w_bckgrnd[dim_red_labels[m][1]].max() + y_xtd\n",
    "                        y_shift = (y_max - y_min) / n_bins\n",
    "                        y_bin_centers = np.linspace(\n",
    "                            start=y_min + 0.5 * y_shift,\n",
    "                            stop=y_max - 0.5 * y_shift,\n",
    "                            num=n_bins\n",
    "                        )\n",
    "                        df_heatmap_sum = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "                        df_heatmap_cnt = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "\n",
    "                        xs = df_bckgrnd.loc[:, dim_red_labels[m][0]].values\n",
    "                        xs_ids = np.floor((xs - x_min) / (x_shift + 1e-10)).astype(int)\n",
    "                        ys = df_bckgrnd.loc[:, dim_red_labels[m][1]].values\n",
    "                        ys_ids = np.floor((ys - y_min) / (y_shift + 1e-10)).astype(int)\n",
    "                        zs = df_bckgrnd.loc[:, trgt].values\n",
    "                        for d_id in range(len(xs_ids)):\n",
    "                            df_heatmap_sum.iat[xs_ids[d_id], ys_ids[d_id]] += zs[d_id]\n",
    "                            df_heatmap_cnt.iat[xs_ids[d_id], ys_ids[d_id]] += 1\n",
    "                        df_heatmap = pd.DataFrame(data=df_heatmap_sum.values / df_heatmap_cnt.values, columns=df_heatmap_sum.columns, index=df_heatmap_sum.index)\n",
    "                        df_heatmap.to_excel(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/heatmap_{trgt}_{m}.xlsx\")\n",
    "\n",
    "                        legend_handles = []\n",
    "                        norm = plt.Normalize(df_dim_red_w_bckgrnd[trgt].min(), df_dim_red_w_bckgrnd[trgt].max())\n",
    "                        sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "                        sm.set_array([])\n",
    "                        fig = plt.figure(figsize=(8, 6))\n",
    "                        sns.set_theme(style='whitegrid')\n",
    "\n",
    "                        plt.gca().imshow(\n",
    "                            X=df_heatmap.transpose().iloc[::-1].values,\n",
    "                            extent=[x_min, x_max, y_min, y_max],\n",
    "                            vmin=df_dim_red_w_bckgrnd[trgt].min(),\n",
    "                            vmax=df_dim_red_w_bckgrnd[trgt].max(),\n",
    "                            aspect=x_shift/y_shift,\n",
    "                            cmap=\"spring\",\n",
    "                            alpha=0.75\n",
    "                        )\n",
    "                        legend_handles.append(mlines.Line2D([], [], marker='s', linestyle='None',markeredgewidth=0, markerfacecolor='lightgrey', markersize=10, label='Background'))\n",
    "\n",
    "                        scatter = sns.scatterplot(\n",
    "                            data=df_dim_red,\n",
    "                            x=dim_red_labels[m][0],\n",
    "                            y=dim_red_labels[m][1],\n",
    "                            palette='spring',\n",
    "                            hue=trgt,\n",
    "                            linewidth=0.5,\n",
    "                            alpha=0.75,\n",
    "                            edgecolor=\"k\",\n",
    "                            marker='o',\n",
    "                            s=50,\n",
    "                        )\n",
    "                        scatter.get_legend().remove()\n",
    "                        legend_handles.append(mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'))\n",
    "\n",
    "                        scatter = sns.scatterplot(\n",
    "                            data=df_dim_red_adv,\n",
    "                            x=dim_red_labels[m][0],\n",
    "                            y=dim_red_labels[m][1],\n",
    "                            palette='spring',\n",
    "                            hue=trgt,\n",
    "                            linewidth=0.5,\n",
    "                            alpha=0.75,\n",
    "                            edgecolor=\"k\",\n",
    "                            marker='X',\n",
    "                            s=50,\n",
    "                        )\n",
    "                        scatter.get_legend().remove()\n",
    "                        legend_handles.append(mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Attack'))\n",
    "\n",
    "                        plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", mode=\"expand\", borderaxespad=0, ncol=3, frameon=False)\n",
    "                        fig.colorbar(sm, label=trgt)\n",
    "                        plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}_w_bckgrnd.png\", bbox_inches='tight', dpi=400)\n",
    "                        plt.savefig(f\"{path_save}/eps_{eps_raw:0.4f}/{attack_type}/{trgt}_{m}_w_bckgrnd.pdf\", bbox_inches='tight')\n",
    "                        plt.close()\n",
    "\n",
    "df_eps.to_excel(f\"{path_save}/df_eps.xlsx\", index_label='eps')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAE from eps plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attacks = {\n",
    "    'MI': \"Momentum Iterative\",\n",
    "    'BI': \"Basic Iterative\",\n",
    "    'PGD': \"Projected Gradient Descent\",\n",
    "    'FG': \"Fast Gradient\"\n",
    "}\n",
    "attacks_palette = {\n",
    "    \"Momentum Iterative\": px.colors.qualitative.D3[0],\n",
    "    \"Basic Iterative\": px.colors.qualitative.D3[1],\n",
    "    \"Projected Gradient Descent\": px.colors.qualitative.D3[2],\n",
    "    \"Fast Gradient\": px.colors.qualitative.D3[3]\n",
    "}\n",
    "df_fig = df_eps.loc[:, [f\"{x}_MAE_Attack\" for x in attacks]].copy()\n",
    "df_fig.rename(columns={f\"{x}_MAE_Attack\": attacks[x] for x in attacks}, inplace=True)\n",
    "df_fig.to_excel(f\"{path_save}/mae_vs_eps.xlsx\", index_label='Eps')\n",
    "df_fig['Eps'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"MAE\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eps',\n",
    "    y=\"MAE\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=attacks_palette,\n",
    "    hue_order=list(attacks_palette.keys()),\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "x_min = 0.009\n",
    "x_max = 1.05\n",
    "mae_basic = df_eps.at[0.01, \"MI_MAE_Origin\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [mae_basic, mae_basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path_save}/mae_vs_eps.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_save}/mae_vs_eps.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attacks = {\n",
    "    'MI': \"Momentum Iterative\",\n",
    "    'BI': \"Basic Iterative\",\n",
    "    'PGD': \"Projected Gradient Descent\",\n",
    "    'FG': \"Fast Gradient\"\n",
    "}\n",
    "for attack in attacks:\n",
    "    df_fig = df_eps.loc[:, [f\"{attack}_{sample}_ErrorDiff\" for sample in ids_trgt]].copy()\n",
    "    for sample in ids_trgt:\n",
    "        func = interp1d(df_fig.index, df_fig[f\"{attack}_{sample}_ErrorDiff\"], kind='cubic')\n",
    "        df_fig[f\"{attack}_{sample}_ErrorDiff\"] = func(df_fig.index)\n",
    "\n",
    "    df_fig['Eps'] = df_fig.index.values\n",
    "    df_fig = df_fig.melt(id_vars=\"Eps\", var_name='ID', value_name=\"Error(Attack) - Error(Origin)\")\n",
    "    fig = plt.figure()\n",
    "    sns.set_theme(style='whitegrid', font_scale=1)\n",
    "    lines = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x='Eps',\n",
    "        y=\"Error(Attack) - Error(Origin)\",\n",
    "        hue=f\"ID\",\n",
    "        markers=False,\n",
    "        dashes=False,\n",
    "        legend=False,\n",
    "        linewidth=0.2,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    plt.savefig(f\"{path_save}/{attack}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path_save}/{attack}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
