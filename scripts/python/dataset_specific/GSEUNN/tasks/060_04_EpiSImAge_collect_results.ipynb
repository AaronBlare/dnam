{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=False)\n",
    "import itertools\n",
    "from scipy.stats import mannwhitneyu, median_test, kruskal, wilcoxon, friedmanchisquare\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as path_effects\n",
    "import random\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from src.utils.plot.bioinfokit import mhat, volcano\n",
    "import gseapy as gp\n",
    "import mygene\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap, TSNE, LocallyLinearEmbedding\n",
    "import upsetplot\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "from itertools import chain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scripts.python.routines.plot.colorscales import get_continuous_color\n",
    "from impyute.imputation.cs import fast_knn\n",
    "import plotly\n",
    "from scripts.python.routines.plot.p_value import add_p_value_annotation\n",
    "from scripts.python.routines.sections import get_sections\n",
    "from statannotations.Annotator import Annotator\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import functools\n",
    "from src.models.tabular.base import get_model_framework_dict\n",
    "import matplotlib.lines as mlines\n",
    "import patchworklib as pw\n",
    "from glob import glob\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from pathlib import Path\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from src.models.tabular.widedeep.tab_mlp import WDTabMLPModel\n",
    "from src.models.tabular.widedeep.tab_net import WDTabNetModel\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoost\n",
    "import pickle\n",
    "from src.tasks.metrics import get_reg_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.*\")\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Immunomarkers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "feat_imm = 'IL27'\n",
    "model = 'widedeep_tab_mlp'\n",
    "\n",
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/060_EpiSImAge/fimmu_features\"\n",
    "path_runs = f\"{path}/{feat_imm}/models/{model}_trn_val_tst/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    \n",
    "    df_res.at[file, 'index'] = head.replace(path_runs, '')\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_metrics.at[metric, \"val\"]\n",
    "        df_res.at[file, metric + \"_trn\"] = df_metrics.at[metric, \"trn\"]\n",
    "        df_res.at[file, metric + \"_tst\"] = df_metrics.at[metric, \"tst\"]\n",
    "        df_res.at[file, metric + \"_trn_val\"] = df_metrics.at[metric, \"trn_val\"]\n",
    "        df_res.at[file, metric + \"_val_tst\"] = df_metrics.at[metric, \"val_tst\"]\n",
    "        df_res.at[file, metric + \"_trn_val_tst\"] = df_metrics.at[metric, \"trn_val_tst\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res.set_index('index', inplace=True)\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = {\n",
    "    'selected': 'selected',\n",
    "    'train_more_val': 'train_more_val',\n",
    "    'mean_absolute_error_trn': 'MAE trn',\n",
    "    'mean_absolute_error_val': 'MAE val',\n",
    "    'mean_absolute_error_tst': 'MAE tst',\n",
    "    'mean_absolute_error_val_tst': 'MAE val_tst',\n",
    "    'mean_absolute_error_trn_val_tst': 'MAE trn_val_tst',\n",
    "    'pearson_corr_coef_trn': 'Pcorr trn',\n",
    "    'pearson_corr_coef_val': 'Pcorr val',\n",
    "    'pearson_corr_coef_tst': 'Pcorr tst',\n",
    "    'pearson_corr_coef_val_tst': 'Pcorr val_tst',\n",
    "    'pearson_corr_coef_trn_val_tst': 'Pcorr trn_val_tst',\n",
    "    'mean_absolute_error_cv_mean_trn': 'MAE cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn': 'MAE cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val': 'MAE cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val': 'MAE cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_trn': 'Pcorr cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn': 'Pcorr cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_val': 'Pcorr cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val': 'Pcorr cv_std_val',\n",
    "}\n",
    "df_res = df_res[list(first_columns.keys()) + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.rename(columns=first_columns, inplace=True)\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EpiSImAge calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_epi_feats = 100\n",
    "\n",
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/060_EpiSImAge\"\n",
    "feats_imm_fimmu = pd.read_excel(f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "\n",
    "best_files = {\n",
    "    'CXCL9': f\"{path}/fimmu_features/CXCL9/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-07_23-55-29_1337/354/best_fold_0005.ckpt\",\n",
    "    'CCL22': f\"{path}/fimmu_features/CCL22/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-09_12-39-48_1337/40/best_fold_0004.ckpt\",\n",
    "    'IL6': f\"{path}/fimmu_features/IL6/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-10_02-07-13_1337/110/best_fold_0004.ckpt\",\n",
    "    'PDGFB': f\"{path}/fimmu_features/PDGFB/models/lightgbm_trn_val_tst/multiruns/2024-03-10_12-48-20_1337/156/epoch_13_best_0006.model\",\n",
    "    'CD40LG': f\"{path}/fimmu_features/CD40LG/models/lightgbm_trn_val_tst/multiruns/2024-03-10_12-37-12_1337/464/epoch_22_best_0000.model\",\n",
    "    'IL27': f\"{path}/fimmu_features/IL27/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-10_16-53-13_1337/122/best_fold_0000.ckpt\",\n",
    "    'VEGFA': f\"{path}/fimmu_features/VEGFA/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-10_16-06-26_1337/310/best_fold_0005.ckpt\",\n",
    "    'CSF1': f\"{path}/fimmu_features/CSF1/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-10_16-50-13_1337/103/best_fold_0005.ckpt\",\n",
    "    'PDGFA': f\"{path}/fimmu_features/PDGFA/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-09_23-31-10_1337/27/best_fold_0003.ckpt\",\n",
    "    'CXCL10': f\"{path}/fimmu_features/CXCL10/models/widedeep_tab_mlp_trn_val_tst/multiruns/2024-03-09_12-20-47_1337/426/best_fold_0000.ckpt\"\n",
    "}\n",
    "\n",
    "files_all_list = []\n",
    "for feat_imm in feats_imm_fimmu:\n",
    "    if feat_imm in ['CXCL9', 'CCL22', 'IL6', 'PDGFB', 'CD40LG']:\n",
    "        files = glob(f\"{path}/fimmu_features/{feat_imm}/models/*/*/*/*/epoch_*.model\") + glob(f\"{path}/fimmu_features/{feat_imm}/models/*/*/*/*/best_fold_*.ckpt\")\n",
    "        files_all_list.append(files)\n",
    "    else:\n",
    "        files_all_list.append([best_files[feat_imm]])\n",
    "        \n",
    "files_all_dicts = [dict(zip(feats_imm_fimmu, elem)) for elem in itertools.product(*files_all_list)]\n",
    "\n",
    "model_simage = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/data/immuno/models/SImAge/best_fold_0002.ckpt\")\n",
    "model_simage.eval()\n",
    "model_simage.freeze()\n",
    "\n",
    "data_parts = ['GSEUNN', 'GSE87571', 'GSE40279']\n",
    "dfs_tst = {}\n",
    "for data_part in data_parts:\n",
    "    df_pheno = pd.read_csv(f\"{path}/{data_part}/pheno.csv\", index_col=0)\n",
    "    if data_part == 'GSEUNN':\n",
    "        df_pheno.set_index(\"index\", inplace=True)\n",
    "        df_pheno = df_pheno.loc[df_pheno['Status'] == 'Control', :]\n",
    "    elif data_part == 'GSE40279':\n",
    "        df_pheno.set_index(\"gsm\", inplace=True)\n",
    "    df_betas = pd.read_pickle(f\"{path}/{data_part}/betas.pkl\")\n",
    "    dfs_tst[data_part] = pd.merge(df_pheno.loc[:, ['Age']], df_betas, left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_combos_metrics = pd.DataFrame(index=range(len(files_all_dicts)))\n",
    "for combo_id, combo in tqdm(enumerate(files_all_dicts), total=len(files_all_dicts)):\n",
    "    df_imm_data = {}\n",
    "    for data_part in data_parts:\n",
    "        df_imm_data[data_part] = pd.DataFrame(columns=feats_imm_fimmu)\n",
    "        df_imm_data[data_part]['Age'] = dfs_tst[data_part].loc[:, 'Age'].values\n",
    "    \n",
    "    for feat_imm in feats_imm_fimmu:\n",
    "        \n",
    "        feats_epi = pd.read_excel(f\"{path}/fimmu_features/{feat_imm}/feats_con_{n_epi_feats}.xlsx\", index_col=0).index.values\n",
    "        \n",
    "        X = {}\n",
    "        y_pred = {}\n",
    "        for data_part in data_parts:\n",
    "            X[data_part] = dfs_tst[data_part].loc[:, feats_epi].values\n",
    "        \n",
    "        file = combo[feat_imm]\n",
    "        df_combos_metrics.at[combo_id, feat_imm] = '/'.join(Path(file).parts[-5::])\n",
    "        \n",
    "        model_type = Path(file).parts[-5].replace('_trn_val_tst', '')\n",
    "        model_framework_dict = get_model_framework_dict()\n",
    "        model_framework = model_framework_dict[model_type]\n",
    "        \n",
    "        if model_framework == \"pytorch\":\n",
    "            if model_type == \"widedeep_tab_mlp\":\n",
    "                model = WDTabMLPModel.load_from_checkpoint(checkpoint_path=file)\n",
    "                model.eval()\n",
    "                model.freeze()\n",
    "            for data_part in data_parts:\n",
    "                y_pred[data_part] = model(torch.from_numpy(X[data_part])).cpu().detach().numpy().ravel()\n",
    "        \n",
    "        elif model_framework == \"stand_alone\":\n",
    "            if model_type == \"xgboost\":\n",
    "                model = xgb.Booster()\n",
    "                model.load_model(file)\n",
    "                for data_part in data_parts:\n",
    "                    dmat = xgb.DMatrix(X[data_part], feature_names=feats_epi, enable_categorical=True)\n",
    "                    y_pred[data_part] = model.predict(dmat)\n",
    "        \n",
    "            elif model_type == \"catboost\":\n",
    "                model = CatBoost()\n",
    "                model.load_model(file)\n",
    "                for data_part in data_parts:\n",
    "                    y_pred[data_part] = model.predict(X[data_part]).astype('float32')\n",
    "        \n",
    "            elif model_type == \"lightgbm\":\n",
    "                model = lgb.Booster(model_file=file)\n",
    "                for data_part in data_parts:\n",
    "                    y_pred[data_part] = model.predict(X[data_part], num_iteration=model.best_iteration).astype('float32')\n",
    "        \n",
    "            elif model_type == \"elastic_net\":\n",
    "                model = pickle.load(open(file, 'rb'))\n",
    "                for data_part in data_parts:\n",
    "                    y_pred[data_part] = model.predict(X[data_part]).astype('float32')\n",
    "        \n",
    "            else:\n",
    "                raise ValueError(f\"Model {model_type} is not supported\")\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_framework: {model_framework}\")\n",
    "        \n",
    "        for data_part in data_parts:\n",
    "            df_imm_data[data_part][feat_imm] = np.exp(y_pred[data_part])\n",
    "    \n",
    "    y = {}\n",
    "    y_pred = {}\n",
    "    for data_part in data_parts:\n",
    "        y[data_part] = df_imm_data[data_part].loc[:, 'Age'].values\n",
    "        y_pred[data_part] = model_simage(torch.from_numpy(df_imm_data[data_part].loc[:, feats_imm_fimmu].values)).cpu().detach().numpy().ravel()\n",
    "        metrics = get_reg_metrics()\n",
    "        for m in metrics:\n",
    "            y_real_torch = torch.from_numpy(np.float32(y[data_part]))\n",
    "            y_pred_torch = torch.from_numpy(y_pred[data_part])\n",
    "            m_val = float(metrics[m][0](y_pred_torch, y_real_torch).numpy())\n",
    "            metrics[m][0].reset()\n",
    "            df_combos_metrics.at[combo_id, f\"{data_part}_{m}\"] = m_val\n",
    "\n",
    "\n",
    "first_columns = [\n",
    "    \"GSEUNN_mean_absolute_error\",\n",
    "    \"GSE87571_mean_absolute_error\",\n",
    "    \"GSE40279_mean_absolute_error\",\n",
    "]\n",
    "df_combos_metrics = df_combos_metrics[first_columns + [col for col in df_combos_metrics.columns if col not in first_columns]]\n",
    "df_combos_metrics.to_excel(f\"{path}/fimmu_features/combos_metrics.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SImAge2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = 'widedeep_tab_mlp'\n",
    "\n",
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/060_EpiSImAge/SImAge2\"\n",
    "path_runs = f\"{path}/models/{model}_trn_val_tst/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    \n",
    "    df_res.at[file, 'index'] = head.replace(path_runs, '')\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_metrics.at[metric, \"val\"]\n",
    "        df_res.at[file, metric + \"_trn\"] = df_metrics.at[metric, \"trn\"]\n",
    "        df_res.at[file, metric + \"_tst\"] = df_metrics.at[metric, \"tst\"]\n",
    "        df_res.at[file, metric + \"_trn_val\"] = df_metrics.at[metric, \"trn_val\"]\n",
    "        df_res.at[file, metric + \"_val_tst\"] = df_metrics.at[metric, \"val_tst\"]\n",
    "        df_res.at[file, metric + \"_trn_val_tst\"] = df_metrics.at[metric, \"trn_val_tst\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res.set_index('index', inplace=True)\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = {\n",
    "    'selected': 'selected',\n",
    "    'train_more_val': 'train_more_val',\n",
    "    'mean_absolute_error_trn': 'MAE trn',\n",
    "    'mean_absolute_error_val': 'MAE val',\n",
    "    'mean_absolute_error_tst': 'MAE tst',\n",
    "    'mean_absolute_error_val_tst': 'MAE val_tst',\n",
    "    'mean_absolute_error_trn_val_tst': 'MAE trn_val_tst',\n",
    "    'pearson_corr_coef_trn': 'Pcorr trn',\n",
    "    'pearson_corr_coef_val': 'Pcorr val',\n",
    "    'pearson_corr_coef_tst': 'Pcorr tst',\n",
    "    'pearson_corr_coef_val_tst': 'Pcorr val_tst',\n",
    "    'pearson_corr_coef_trn_val_tst': 'Pcorr trn_val_tst',\n",
    "    'mean_absolute_error_cv_mean_trn': 'MAE cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn': 'MAE cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val': 'MAE cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val': 'MAE cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_trn': 'Pcorr cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn': 'Pcorr cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_val': 'Pcorr cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val': 'Pcorr cv_std_val',\n",
    "}\n",
    "df_res = df_res[list(first_columns.keys()) + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.rename(columns=first_columns, inplace=True)\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SImAge log"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = 'widedeep_tab_mlp'\n",
    "\n",
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/060_EpiSImAge/SImAge_log\"\n",
    "path_runs = f\"{path}/models/{model}_trn_val_tst/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    \n",
    "    df_res.at[file, 'index'] = head.replace(path_runs, '')\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_metrics.at[metric, \"val\"]\n",
    "        df_res.at[file, metric + \"_trn\"] = df_metrics.at[metric, \"trn\"]\n",
    "        df_res.at[file, metric + \"_tst\"] = df_metrics.at[metric, \"tst\"]\n",
    "        df_res.at[file, metric + \"_trn_val\"] = df_metrics.at[metric, \"trn_val\"]\n",
    "        df_res.at[file, metric + \"_val_tst\"] = df_metrics.at[metric, \"val_tst\"]\n",
    "        df_res.at[file, metric + \"_trn_val_tst\"] = df_metrics.at[metric, \"trn_val_tst\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res.set_index('index', inplace=True)\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = {\n",
    "    'selected': 'selected',\n",
    "    'train_more_val': 'train_more_val',\n",
    "    'mean_absolute_error_trn': 'MAE trn',\n",
    "    'mean_absolute_error_val': 'MAE val',\n",
    "    'mean_absolute_error_tst': 'MAE tst',\n",
    "    'mean_absolute_error_val_tst': 'MAE val_tst',\n",
    "    'mean_absolute_error_trn_val_tst': 'MAE trn_val_tst',\n",
    "    'pearson_corr_coef_trn': 'Pcorr trn',\n",
    "    'pearson_corr_coef_val': 'Pcorr val',\n",
    "    'pearson_corr_coef_tst': 'Pcorr tst',\n",
    "    'pearson_corr_coef_val_tst': 'Pcorr val_tst',\n",
    "    'pearson_corr_coef_trn_val_tst': 'Pcorr trn_val_tst',\n",
    "    'mean_absolute_error_cv_mean_trn': 'MAE cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn': 'MAE cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val': 'MAE cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val': 'MAE cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_trn': 'Pcorr cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn': 'Pcorr cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_val': 'Pcorr cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val': 'Pcorr cv_std_val',\n",
    "}\n",
    "df_res = df_res[list(first_columns.keys()) + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.rename(columns=first_columns, inplace=True)\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
