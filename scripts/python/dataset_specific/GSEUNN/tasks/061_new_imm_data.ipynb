{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=False)\n",
    "from scipy.stats import mannwhitneyu, median_test, kruskal, wilcoxon, friedmanchisquare\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as path_effects\n",
    "import random\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from src.utils.plot.bioinfokit import mhat, volcano\n",
    "import gseapy as gp\n",
    "import mygene\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap, TSNE, LocallyLinearEmbedding\n",
    "import upsetplot\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "from itertools import chain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scripts.python.routines.plot.colorscales import get_continuous_color\n",
    "from impyute.imputation.cs import fast_knn\n",
    "import plotly\n",
    "import torch\n",
    "from scripts.python.routines.plot.p_value import add_p_value_annotation\n",
    "from scripts.python.routines.sections import get_sections\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from statannotations.Annotator import Annotator\n",
    "import functools\n",
    "import matplotlib.lines as mlines\n",
    "import patchworklib as pw\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.*\")\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Update original data with new data from Mirny"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load original data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_save = f\"{path}/special/061_new_imm_data\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Papers\n",
    "df_imm_fimmu = pd.read_excel(f\"{path}/data/immuno/models/SImAge/data.xlsx\", index_col=\"sample_id\")\n",
    "df_imm_geroscience = pd.read_excel(f\"{path}/data/immuno/models/IPAge/11357_2022_540_MOESM12_ESM.xlsx\", index_col=0, skiprows=1)\n",
    "df_epi_clinepi = pd.read_excel(f\"{path}/data/GSE234461/samples.xlsx\", index_col=0)\n",
    "\n",
    "df_ori = pd.read_excel(f\"{path}/data/immuno/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_ld_imm_ori = df_ori['Subject ID'].value_counts().to_frame()\n",
    "df_ori['Is longitudinal?'] = False\n",
    "df_ori.loc[df_ori['Subject ID'].isin(df_ld_imm_ori.index[df_ld_imm_ori['Subject ID'] > 1].values), 'Is longitudinal?'] = True\n",
    "df_ori['Time'] = df_ori['Sample_Chronology']\n",
    "df_ori['Time'].replace({0: 'T0', 1: 'T1', 2: 'T2', 3: 'T3'}, inplace=True)\n",
    "df_ori.loc[df_imm_fimmu.index.values, 'PMC10485620 ID'] = df_imm_fimmu.loc[df_imm_fimmu.index.values, 'index']\n",
    "df_ori.loc[df_imm_geroscience.index.values, 'PMC9135940 ID'] = df_imm_geroscience.loc[df_imm_geroscience.index.values, 'ID_Origin']\n",
    "df_ori.loc[df_epi_clinepi.index.values, 'PMC10699032 ID'] = df_epi_clinepi.loc[df_epi_clinepi.index.values, 'GSM']\n",
    "\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/feats_con.xlsx\", index_col=0).index.values\n",
    "feats_fimmu = pd.read_excel(f\"{path}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "feats_slctd = pd.read_excel(f\"{path}/special/059_imm_data_selection/feats_selected.xlsx\", index_col=0).index.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load SImAge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_simage = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/data/immuno/models/SImAge/best_fold_0002.ckpt\")\n",
    "model_simage.eval()\n",
    "model_simage.freeze()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get original dataframe with nans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"Aging L, Q, H, I\",\n",
    "    \"Aging-Covid_05.01.2022\",\n",
    "    \"Aging-Covid-05.05.22\",\n",
    "    \"Covid_results_02_2021\",\n",
    "    \"Covid-25.11.20\",\n",
    "    \"MULTIPLEX_20_11_2020_ AGING\",\n",
    "    \"Yakutiya + TR\",\n",
    "    \"Мультиплекс_Agind&Covid\",\n",
    "]\n",
    "df_imm_genes = pd.read_excel(f\"{path}/data/immuno/immuno_markers_genes.xlsx\")\n",
    "dict_imm_genes = dict(zip(df_imm_genes['immuno_marker'], df_imm_genes['gene']))\n",
    "\n",
    "dfs_files = []\n",
    "nans_by_features = {}\n",
    "for file in files:\n",
    "    df_file = pd.read_excel(f\"{path}/data/immuno/files/processed/{file}.xlsx\", index_col=\"Sample\")\n",
    "    df_file.rename(columns=dict_imm_genes, inplace=True)\n",
    "    df_file = df_file.loc[:, feats]\n",
    "\n",
    "    # duplicates processing\n",
    "    if file == \"MULTIPLEX_20_11_2020_ AGING\":\n",
    "        df_file_doubled_unique = df_file.loc[~df_file.index.duplicated(keep=False), :]\n",
    "        df_file_doubled_1 = df_file.loc[df_file.index.duplicated(keep='first'), :]\n",
    "        df_file_doubled_2 = df_file.loc[df_file.index.duplicated(keep='last'), :]\n",
    "        df_file_duplicates_final = pd.concat([df_file_doubled_2, df_file_doubled_unique], axis=0)\n",
    "        df_file = df_file_duplicates_final\n",
    "    df_file_duplicates = df_file.loc[df_file.index.duplicated(keep=False), :]\n",
    "    if df_file_duplicates.shape[0] > 0:\n",
    "        print(df_file_duplicates.index)\n",
    "    \n",
    "    for feat in df_file:\n",
    "        nan_vals = set(df_file.loc[df_file[feat].astype(str).str.contains(r'^([<>].*)$', regex=True), feat].values)\n",
    "        if len(nan_vals) > 0:\n",
    "            for nv in nan_vals:\n",
    "                if feat in nans_by_features:\n",
    "                    nans_by_features[feat].add(nv)\n",
    "                else:\n",
    "                    nans_by_features[feat] = {nv}\n",
    "    \n",
    "    dfs_files.append(df_file)\n",
    "\n",
    "df_ori_w_nans = pd.concat(dfs_files, verify_integrity=False)\n",
    "df_ori_w_nans.index = df_ori_w_nans.index.map(str)\n",
    "df_ori_w_nans = df_ori_w_nans.loc[df_ori.index.values, :]\n",
    "df_ori_w_nans.replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "for feat in feats:\n",
    "    ids_imputed_above = df_ori_w_nans.index[df_ori_w_nans[feat].astype(str).str.contains('>')]\n",
    "    df_ori_w_nans.loc[ids_imputed_above, feat] = df_ori.loc[ids_imputed_above, feat]\n",
    "df_ori_w_nans = df_ori_w_nans.apply(pd.to_numeric, errors='coerce')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute thresholds in xponent data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_xpnt_w_nans = pd.read_excel(f\"{path}/data/immuno/files/processed/10-March-2024/48-plex-human-_xPONENT_2024.xlsx\", index_col=\"Sample ID\")\n",
    "df_xpnt_w_nans = df_xpnt_w_nans.loc[df_xpnt_w_nans.index.str.startswith('M', na=False), feats]\n",
    "df_xpnt_w_nans.replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "df_xpnt_w_nans = df_xpnt_w_nans.apply(pd.to_numeric, errors='coerce')\n",
    "df_mirny_pheno = pd.read_excel(f\"{path}/data/immuno/files/processed/10-March-2024/Список Мирный.xlsx\", index_col=0)\n",
    "df_xpnt_w_nans.loc[df_xpnt_w_nans.index.values, ['Age', 'Sex', 'Nationality']] = df_mirny_pheno.loc[df_xpnt_w_nans.index.values, ['Age', 'Sex', 'Nationality']]\n",
    "ids_imp_trn = df_ori.index[(df_ori['Region'] == 'Central') & (df_ori['Status'] == 'Control')]\n",
    "ids_imp_tst = df_xpnt_w_nans.index.values\n",
    "df_imp = pd.concat([\n",
    "    df_ori.loc[ids_imp_trn, feats],\n",
    "    df_xpnt_w_nans.loc[:, feats]\n",
    "])\n",
    "df_imp.loc[:, feats] = df_imp.loc[:, feats].astype('float')\n",
    "imp_vals = fast_knn(df_imp.loc[:, feats].values)\n",
    "df_imp.loc[:, feats] = imp_vals\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "for feat in feats:\n",
    "    srs_feat_base = df_ori_w_nans.loc[ids_imp_trn, feat].isna()\n",
    "    ids_feat_base = srs_feat_base.index[srs_feat_base == True].values\n",
    "    if len(ids_feat_base) > 0:\n",
    "        feat_base_vals = df_ori.loc[ids_feat_base, feat].unique()\n",
    "        srs_feat_trgt = df_xpnt_w_nans.loc[ids_imp_tst, feat].isna()\n",
    "        ids_feat_trgt = srs_feat_trgt.index[srs_feat_trgt == True].values\n",
    "        for id_trgt in ids_feat_trgt:\n",
    "            df_imp.at[id_trgt, feat] = find_nearest(feat_base_vals, df_imp.at[id_trgt, feat])\n",
    "\n",
    "df_xpnt = df_xpnt_w_nans.copy()\n",
    "df_xpnt.loc[ids_imp_tst, feats] = df_imp.loc[ids_imp_tst, feats]\n",
    "df_xpnt['Region'] = 'Mirny'\n",
    "df_xpnt['Time'] = 'T0'\n",
    "df_xpnt['Sample_Chronology'] = 0\n",
    "df_xpnt['Is longitudinal?'] = False\n",
    "df_xpnt['Status'] = 'Control'\n",
    "df_xpnt['file'] = '48-plex-human-_xPONENT_2024.xlsx'\n",
    "df_xpnt['Subject ID'] = df_xpnt.index.values\n",
    "df_xpnt['SImAge'] = model_simage(torch.from_numpy(df_xpnt.loc[:, feats_fimmu].values)).cpu().detach().numpy().ravel()\n",
    "df_xpnt['SImAge acceleration'] = df_xpnt['SImAge'] - df_xpnt['Age']\n",
    "df_xpnt['|SImAge acceleration|'] = df_xpnt['SImAge acceleration'].abs()\n",
    "for f in feats:\n",
    "    df_xpnt[f\"{f}_log\"] = np.log(df_xpnt[f\"{f}\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge xponent data it with the original data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_ori, df_xpnt], verify_integrity=True)\n",
    "df_all.to_excel(f\"{path_save}/df_all.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process analyst data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "files_nlst = ['plate_1_analyst_2024', 'plate_2_analyst_2024', 'plate_3_analyst_2024']\n",
    "dfs_nlst = []\n",
    "for file in files_nlst:\n",
    "    df_nlst_file = pd.read_excel(f\"{path}/data/immuno/files/processed/10-March-2024/{file}.xlsx\", index_col=\"Sample ID\")\n",
    "    df_nlst_file = df_nlst_file.loc[df_nlst_file.index.str.startswith('M', na=False), feats]\n",
    "    dfs_nlst.append(df_nlst_file) \n",
    "df_nlst_w_nans = pd.concat(dfs_nlst, verify_integrity=True)\n",
    "df_nlst_w_nans.replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "df_nlst_w_nans = df_nlst_w_nans.apply(pd.to_numeric, errors='coerce')\n",
    "df_mirny_pheno = pd.read_excel(f\"{path}/data/immuno/files/processed/10-March-2024/Список Мирный.xlsx\", index_col=0)\n",
    "df_nlst_w_nans.loc[df_nlst_w_nans.index.values, ['Age', 'Sex', 'Nationality']] = df_mirny_pheno.loc[df_nlst_w_nans.index.values, ['Age', 'Sex', 'Nationality']]\n",
    "ids_imp_trn = df_ori.index[(df_ori['Region'] == 'Central') & (df_ori['Status'] == 'Control')]\n",
    "ids_imp_tst = df_nlst_w_nans.index.values\n",
    "df_imp = pd.concat([\n",
    "    df_ori.loc[ids_imp_trn, feats],\n",
    "    df_nlst_w_nans.loc[:, feats]\n",
    "])\n",
    "df_imp.loc[:, feats] = df_imp.loc[:, feats].astype('float')\n",
    "imp_vals = fast_knn(df_imp.loc[:, feats].values)\n",
    "df_imp.loc[:, feats] = imp_vals\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "for feat in feats:\n",
    "    srs_feat_base = df_ori_w_nans.loc[ids_imp_trn, feat].isna()\n",
    "    ids_feat_base = srs_feat_base.index[srs_feat_base == True].values\n",
    "    if len(ids_feat_base) > 0:\n",
    "        feat_base_vals = df_ori.loc[ids_feat_base, feat].unique()\n",
    "        srs_feat_trgt = df_nlst_w_nans.loc[ids_imp_tst, feat].isna()\n",
    "        ids_feat_trgt = srs_feat_trgt.index[srs_feat_trgt == True].values\n",
    "        for id_trgt in ids_feat_trgt:\n",
    "            df_imp.at[id_trgt, feat] = find_nearest(feat_base_vals, df_imp.at[id_trgt, feat])\n",
    "\n",
    "df_nlst = df_nlst_w_nans.copy()\n",
    "df_nlst.loc[ids_imp_tst, feats] = df_imp.loc[ids_imp_tst, feats]\n",
    "df_nlst['Region'] = 'Mirny'\n",
    "df_nlst['Time'] = 'T0'\n",
    "df_nlst['Sample_Chronology'] = 0\n",
    "df_nlst['Is longitudinal?'] = False\n",
    "df_nlst['Status'] = 'Control'\n",
    "df_nlst['file'] = '48-plex-human-_xPONENT_2024.xlsx'\n",
    "df_nlst['Subject ID'] = df_nlst.index.values\n",
    "df_nlst['SImAge'] = model_simage(torch.from_numpy(df_nlst.loc[:, feats_fimmu].values)).cpu().detach().numpy().ravel()\n",
    "df_nlst['SImAge acceleration'] = df_nlst['SImAge'] - df_nlst['Age']\n",
    "df_nlst['|SImAge acceleration|'] = df_nlst['SImAge acceleration'].abs()\n",
    "for f in feats:\n",
    "    df_nlst[f\"{f}_log\"] = np.log(df_nlst[f\"{f}\"])\n",
    "\n",
    "df_nlst.to_excel(f\"{path_save}/df_nlst.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data differences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reload all data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_save = f\"{path}/special/061_new_imm_data\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/feats_con.xlsx\", index_col=0).index.values\n",
    "feats_fimmu = pd.read_excel(f\"{path}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "feats_slctd = pd.read_excel(f\"{path}/special/059_imm_data_selection/feats_selected.xlsx\", index_col=0).index.values\n",
    "\n",
    "df_ori = pd.read_excel(f\"{path}/data/immuno/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_ori['Program'] = 'xponent'\n",
    "df_nlst = pd.read_excel(f\"{path_save}/df_nlst.xlsx\", index_col=0)\n",
    "df_nlst.index += '_nlst'\n",
    "df_nlst['Program'] = 'analyst'\n",
    "\n",
    "df = pd.concat([df_ori, df_nlst])\n",
    "\n",
    "files = [\n",
    "    \"Aging L, Q, H, I\",\n",
    "    \"Aging-Covid_05.01.2022\",\n",
    "    \"Aging-Covid-05.05.22\",\n",
    "    \"Covid_results_02_2021\",\n",
    "    \"Covid-25.11.20\",\n",
    "    \"MULTIPLEX_20_11_2020_ AGING\",\n",
    "    \"Yakutiya + TR\",\n",
    "    \"Мультиплекс_Agind&Covid\",\n",
    "    \"10-March-2024/48-plex-human-_xPONENT_2024\", \n",
    "    \"10-March-2024/plate_1_analyst_2024\",\n",
    "    \"10-March-2024/plate_2_analyst_2024\", \n",
    "    \"10-March-2024/plate_3_analyst_2024\", \n",
    "]\n",
    "df_imm_genes = pd.read_excel(f\"{path}/data/immuno/immuno_markers_genes.xlsx\")\n",
    "dict_imm_genes = dict(zip(df_imm_genes['immuno_marker'], df_imm_genes['gene']))\n",
    "\n",
    "dfs_files = []\n",
    "nans_by_features = {}\n",
    "for file in files:\n",
    "    if file in [\"10-March-2024/48-plex-human-_xPONENT_2024\", \"10-March-2024/plate_1_analyst_2024\", \"10-March-2024/plate_2_analyst_2024\", \"10-March-2024/plate_3_analyst_2024\"]:\n",
    "        df_file = pd.read_excel(f\"{path}/data/immuno/files/processed/{file}.xlsx\", index_col=0)\n",
    "    else:\n",
    "        df_file = pd.read_excel(f\"{path}/data/immuno/files/processed/{file}.xlsx\", index_col=\"Sample\")\n",
    "    df_file.rename(columns=dict_imm_genes, inplace=True)\n",
    "    df_file = df_file.loc[:, feats]\n",
    "\n",
    "    # duplicates processing\n",
    "    if file == \"MULTIPLEX_20_11_2020_ AGING\":\n",
    "        df_file_doubled_unique = df_file.loc[~df_file.index.duplicated(keep=False), :]\n",
    "        df_file_doubled_1 = df_file.loc[df_file.index.duplicated(keep='first'), :]\n",
    "        df_file_doubled_2 = df_file.loc[df_file.index.duplicated(keep='last'), :]\n",
    "        df_file_duplicates_final = pd.concat([df_file_doubled_2, df_file_doubled_unique], axis=0)\n",
    "        df_file = df_file_duplicates_final\n",
    "    elif file == \"10-March-2024/48-plex-human-_xPONENT_2024\":\n",
    "        df_file = df_file.loc[df_file.index.str.startswith('M', na=False), :]\n",
    "    elif file in [\"10-March-2024/plate_1_analyst_2024\", \"10-March-2024/plate_2_analyst_2024\", \"10-March-2024/plate_3_analyst_2024\"]:\n",
    "        df_file = df_file.loc[df_file.index.str.startswith('M', na=False), :]\n",
    "        df_file.index += '_nlst'\n",
    "    df_file_duplicates = df_file.loc[df_file.index.duplicated(keep=False), :]\n",
    "    if df_file_duplicates.shape[0] > 0:\n",
    "        print(df_file_duplicates.index)\n",
    "        \n",
    "    for feat in df_file:\n",
    "        nan_vals = set(df_file.loc[df_file[feat].astype(str).str.contains(r'^([<>].*)$', regex=True), feat].values)\n",
    "        if len(nan_vals) > 0:\n",
    "            for nv in nan_vals:\n",
    "                if feat in nans_by_features:\n",
    "                    nans_by_features[feat].add(nv)\n",
    "                else:\n",
    "                    nans_by_features[feat] = {nv}\n",
    "    \n",
    "    dfs_files.append(df_file)\n",
    "\n",
    "df_w_nans = pd.concat(dfs_files, verify_integrity=False)\n",
    "df_w_nans.index = df_w_nans.index.map(str)\n",
    "df_w_nans = df_w_nans.loc[df.index.values, :]\n",
    "df_w_nans.replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "for feat in feats:\n",
    "    ids_imputed_above = df_w_nans.index[df_w_nans[feat].astype(str).str.contains('>')]\n",
    "    df_w_nans.loc[ids_imputed_above, feat] = df.loc[ids_imputed_above, feat]\n",
    "df_w_nans = df_w_nans.apply(pd.to_numeric, errors='coerce')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
