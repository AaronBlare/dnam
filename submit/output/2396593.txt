args:
 --multirun project_name=tabnet_1 hparams_search=tabnet logger.wandb.offline=True experiment=tabnet work_dir=/home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.005/models/tabnet_1 data_dir=/home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.005 datamodule.path=/home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.005 
[32m[I 2021-09-07 14:58:06,142][0m A new study created in memory with name: no-name-1dfae5c4-67fa-411d-b67f-27043645dd5e[0m
[[36m2021-09-07 14:58:06,143[0m][[35mHYDRA[0m] Study name: no-name-1dfae5c4-67fa-411d-b67f-27043645dd5e[0m
[[36m2021-09-07 14:58:06,143[0m][[35mHYDRA[0m] Storage: None[0m
[[36m2021-09-07 14:58:06,143[0m][[35mHYDRA[0m] Sampler: TPESampler[0m
[[36m2021-09-07 14:58:06,143[0m][[35mHYDRA[0m] Directions: ['maximize'][0m
[[36m2021-09-07 14:58:06,348[0m][[35mHYDRA[0m] Launching 1 jobs locally[0m
[[36m2021-09-07 14:58:06,348[0m][[35mHYDRA[0m] 	#0 : model.n_d=8 model.n_a=8 model.n_steps=6 model.n_independent=3 model.n_shared=2 model.lambda_sparse=0.001 model.optimizer_lr=0.001 model.optimizer_weight_decay=0.001 project_name=tabnet_1 hparams_search=tabnet logger.wandb.offline=True experiment=tabnet work_dir=/home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.005/models/tabnet_1 data_dir=/home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.005 datamodule.path=/home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.005[0m
[[36m2021-09-07 14:58:12,754[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Disabling python warnings! <config.ignore_warnings=True>[0m
CONFIG                                                                          
â”œâ”€â”€ trainer                                                                     
â”‚   â””â”€â”€ max_epochs: 500                                                         
â”‚       patience: 100                                                           
â”‚       batch_size: 128                                                         
â”‚       virtual_batch_size: 64                                                  
â”‚                                                                               
â”œâ”€â”€ model                                                                       
â”‚   â””â”€â”€ _target_: pytorch_tabnet.tab_model.TabNetClassifier                     
â”‚       n_d: 8                                                                  
â”‚       n_a: 8                                                                  
â”‚       n_steps: 6                                                              
â”‚       n_independent: 3                                                        
â”‚       n_shared: 2                                                             
â”‚       momentum: 0.02                                                          
â”‚       lambda_sparse: 0.001                                                    
â”‚       seed: 0                                                                 
â”‚       optimizer_lr: 0.001                                                     
â”‚       optimizer_weight_decay: 0.001                                           
â”‚       scheduler_step_size: 10                                                 
â”‚       scheduler_gamma: 0.9                                                    
â”‚       mask_type: sparsemax                                                    
â”‚       n_output: 4                                                             
â”‚                                                                               
â”œâ”€â”€ datamodule                                                                  
â”‚   â””â”€â”€ _target_: src.datamodules.dnam.betas_pheno.BetasPhenoDataModule         
â”‚       path: /home/yusipov_i/data/dnam/datasets/meta/BrainDiseases/variance_0.0
â”‚       outcome: Status                                                         
â”‚       batch_size: 30                                                          
â”‚       train_val_test_split:                                                   
â”‚       - 0.8                                                                   
â”‚       - 0.1                                                                   
â”‚       - 0.1                                                                   
â”‚       num_workers: 0                                                          
â”‚       pin_memory: false                                                       
â”‚       seed: 42                                                                
â”‚       weighted_sampler: false                                                 
â”‚                                                                               
â”œâ”€â”€ callbacks                                                                   
â”‚   â””â”€â”€ {}                                                                      
â”‚                                                                               
â”œâ”€â”€ logger                                                                      
â”‚   â””â”€â”€ csv:                                                                    
â”‚         _target_: pytorch_lightning.loggers.csv_logs.CSVLogger                
â”‚         save_dir: .                                                           
â”‚         name: csv/                                                            
â”‚         version: null                                                         
â”‚         prefix: ''                                                            
â”‚       wandb:                                                                  
â”‚         _target_: pytorch_lightning.loggers.wandb.WandbLogger                 
â”‚         project: dnam                                                         
â”‚         version: 0                                                            
â”‚         name: null                                                            
â”‚         save_dir: .                                                           
â”‚         offline: true                                                         
â”‚         id: null                                                              
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         job_type: train                                                       
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚                                                                               
â””â”€â”€ seed                                                                        
    â””â”€â”€ 1337                                                                    
[[36m2021-09-07 14:58:12,852[0m][[34mpytorch_lightning.utilities.seed[0m][[32mINFO[0m] - Global seed set to 1337[0m
[[36m2021-09-07 14:58:12,861[0m][[34mtabnet.train[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodules.dnam.betas_pheno.BetasPhenoDataModule>[0m
[[36m2021-09-07 14:58:24,345[0m][[34msrc.datamodules.dnam.betas_pheno[0m][[32mINFO[0m] - total_count: 3654[0m
[[36m2021-09-07 14:58:24,346[0m][[34msrc.datamodules.dnam.betas_pheno[0m][[32mINFO[0m] - train_count: 2922[0m
[[36m2021-09-07 14:58:24,347[0m][[34msrc.datamodules.dnam.betas_pheno[0m][[32mINFO[0m] - val_count: 366[0m
[[36m2021-09-07 14:58:24,347[0m][[34msrc.datamodules.dnam.betas_pheno[0m][[32mINFO[0m] - test_count: 366[0m
[[36m2021-09-07 14:58:24,348[0m][[34mtabnet.train[0m][[32mINFO[0m] - Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>[0m
[[36m2021-09-07 14:58:24,351[0m][[34mtabnet.train[0m][[32mINFO[0m] - Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>[0m
Device used : cpu
[[36m2021-09-07 14:58:27,148[0m][[34mtabnet.train[0m][[32mINFO[0m] - Logging hyperparameters![0m
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id nwujsxmx.
wandb: W&B syncing is set to `offline` in this directory.  Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
epoch 0  | loss: 1.90111 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:06:57s
epoch 1  | loss: 1.78388 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:13:52s
epoch 2  | loss: 1.78618 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:20:45s
epoch 3  | loss: 1.72931 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:27:40s
epoch 4  | loss: 1.71535 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:34:33s
epoch 5  | loss: 1.67522 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:41:25s
epoch 6  | loss: 1.63164 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:48:00s
epoch 7  | loss: 1.59343 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  0:54:35s
epoch 8  | loss: 1.57478 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  1:01:12s
epoch 9  | loss: 1.55761 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  1:07:58s
epoch 10 | loss: 1.54516 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  1:14:34s
epoch 11 | loss: 1.50407 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  1:21:07s
epoch 12 | loss: 1.48357 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  1:27:37s
epoch 13 | loss: 1.45814 | train_accuracy_macro: 0.25    | train_accuracy_weighted: 0.22245 | train_f1_macro: 0.25    | train_cohen_kappa: 0.0     | train_matthews_corrcoef: nan     | train_f1_weighted: 0.22245 | test_accuracy_macro: 0.25    | test_accuracy_weighted: 0.22131 | test_f1_macro: 0.25    | test_cohen_kappa: 0.0     | test_matthews_corrcoef: nan     | test_f1_weighted: 0.22131 | val_accuracy_macro: 0.25    | val_accuracy_weighted: 0.22131 | val_f1_macro: 0.25    | val_cohen_kappa: 0.0     | val_matthews_corrcoef: nan     | val_f1_weighted: 0.22131 |  1:34:08s
slurmstepd: error: *** STEP 2396593.0 ON node66 CANCELLED AT 2021-09-07T17:35:14 ***
slurmstepd: error: *** JOB 2396593 ON node66 CANCELLED AT 2021-09-07T17:35:14 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
/home/yusipov_i/.conda/envs/py38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
srun: got SIGCONT
srun: forcing job termination
srun: error: node66: task 0: Terminated
